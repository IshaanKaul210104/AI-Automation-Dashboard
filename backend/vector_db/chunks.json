[
  {
    "text": "​\n \n​ \n ​\n \n ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n  \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nYour Intermediate Guide to SQL \nAs you get more comfortable with SQL, you will be able to take on even more advanced queries. This \nin-depth guide will give you a more detailed introduction to some of the SQL functions you have \nalready learned, and give you some new tools to work with. Be sure to save this guide, so you can easily \nreference these helpful tips in the future. \nSQL Structure for More Complex Queries \nYou will learn more about these clauses and expressions in the sections below, but first let’s check out \nhow you might structure a more involved SQL query: \nSELECT \nColumn you want to look at \nFROM \nTable the da",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "rn more about these clauses and expressions in the sections below, but first let’s check out \nhow you might structure a more involved SQL query: \nSELECT \nColumn you want to look at \nFROM \nTable the data lives in \nWHERE \nCertain condition on the data \nGROUP BY \nColumn you want to aggregate by \nHAVING \nCertain condition on the aggregation \nORDER BY \nColumn you want to order results by \nand in ASCending or DESCending order \nLIMIT \nThe maximum number of rows you want \nyour results to contain \nDifferent types of JOINs \nMost analysts will use either INNER JOINs or LEFT JOINs throughout their career. When you join \ntables, you are combining data from one table with data in another table connected by a common field. \nFor example, let’s say you have your friends’ favorite colors in one table and your friends’ favorite \nmovies in another table. You can have both of their favorite colors and movies in one table by joining \nthe two tables on your friends’ names, which is the field they have in common. This is your JOIN field. In \nthe workplace, a JOIN field is usually some sort of ID, like a customer_id or account_id. \nTable view \nFavorite_Colors \nFavorite_Movies \nfriend (string) \nfriend (stri",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "mon. This is your JOIN field. In \nthe workplace, a JOIN field is usually some sort of ID, like a customer_id or account_id. \nTable view \nFavorite_Colors \nFavorite_Movies \nfriend (string) \nfriend (string) \ncolor (string) \nmovie (string) \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n​\n​\n \n \n​\n​\n​\n​\n \n \n \n \n \n \nData view \nFavorite_Colors \nfriend \ncolor \nRachel DeSantos \nblue \nSujin Lee \ngreen \nNajil Okoro \nred \nJohn Anderson \norange \nFavorite_Movies \nfriend \nmovie \nRachel DeSantos \nAvengers \nSujin Lee \nDespicable Me \nNajil Okoro \nFrozen \nSo, in this example, you would want to use an INNER JOIN if you only want to see information for friends \nwho have both a favorite color and a favorite movie. That means if John Anderson has a favorite color \nbut no favorite movie, John Anderson won’t show up in your results. Friends have to be in both tables to \nshow up in your results. So INNER JOINs are useful when you want to see data where the JOIN key \nexis",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "favorite movie, John Anderson won’t show up in your results. Friends have to be in both tables to \nshow up in your results. So INNER JOINs are useful when you want to see data where the JOIN key \nexists in both tables, which is usually why you want to join datasets in the first place. Typically, analysts \nwill use INNER JOINs most of the time. \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \nFavorite_Movies AS m ON c.friend = m.friend \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n  \n  \n  \n ​\n​   \n \n  \n ​\n​  ​\n​ \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nResults: \nfriend \ncolor \nmovie \nRachel DeSantos \nblue \nAvengers \nSujin Lee \ngreen \nDespicable Me \nNajil Okoro \nr",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Results: \nfriend \ncolor \nmovie \nRachel DeSantos \nblue \nAvengers \nSujin Lee \ngreen \nDespicable Me \nNajil Okoro \nred \nFrozen \nSince this query used an INNER JOIN, the results only have three out of the four friends. As a quick \nreminder, that is because INNER JOIN queries only return results where the JOIN field—in this case \n“friend”—exists in both tables. Since John Anderson doesn’t exist in the favorite movies table, he is \nexcluded from the query results. \nNow, let’s say you want to use a LEFT JOIN to get information for all of your friends into one table (e.g. \nfavorite colors table) with data added from the other table (e.g. favorite movies table) if it exists. So, if \nJohn Anderson has a favorite color but no favorite movie, he will still show up in your results. He will just \nhave an empty field (which is null) for his favorite movie. Most of the time LEFT JOINs are used if the \ndata you are trying to pull in from another table is optional. This is a nice-to-have field but not necessary \nfor your analysis since you may get nulls. On the job, you will find that analysts will use LEFT JOINs",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "rying to pull in from another table is optional. This is a nice-to-have field but not necessary \nfor your analysis since you may get nulls. On the job, you will find that analysts will use LEFT JOINs less \noften than INNER JOINs. \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nLEFT JOIN \nFavorite_Movies AS m ON c.friend = m.friend \nResults: \nfriend \ncolor \nmovie \nRachel DeSantos \nblue \nAvengers \nSujin Lee \ngreen \nDespicable Me \nNajil Okoro \nred \nFrozen \nJohn Anderson \norange \nnull \nSo now you know the difference between INNER JOINs and LEFT JOINs. You know that INNER JOINs \nwill be the most commonly used JOIN types because they usually align with business use cases. \nAnother reason that INNER JOINs are used is because they result in less data since the JOIN key must \nexist in both tables. This means that queries with INNER JOINs tend to run faster and use less resources \n\n\n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n ​\n​ \n ​\n​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n​ \n ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n \n \n \n \n \nthan queries with LEFT JOINs. This might not be a problem for most analysts, but if you are working with \nvery large tables that have 1+ million rows and/or depending on the SQL dialect used, your query might \ntake a lot longer to run if you use a LEFT JOIN instead of an INNER JOIN. \nBasically, the takeaway here is to use INNER JOINs as much as you can. \nAggregators like SUM() and COUNT() \nAggregators summarize rows into a single value. The functions SUM() and COUNT() are examples of \naggregators. The types of aggregators that will be available for you will depend on the SQL dialect that \nyour company uses. But the most commonly used aggregators like SUM(), COUNT(), MAX(), and MIN() \nare available in all SQL",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ggregators that will be available for you will depend on the SQL dialect that \nyour company uses. But the most commonly used aggregators like SUM(), COUNT(), MAX(), and MIN() \nare available in all SQL dialects, even if there are some slight differences. It is easy to check how \naggregators are formatted for whatever dialect you are working with. There are a lot of resources \navailable online. Just open up your favorite search engine and search for the aggregate function that \nyou want to use and your SQL dialect. For example, search for “SUM function in SQL Server.” \nAggregators all work the same way, so let’s go over SUM() and COUNT(). The SUM() function takes a \nsum of whatever column you put inside the parentheses. The COUNT() function counts the number of \nentries in whatever column you put inside the parentheses. For example, let’s say you have a purchase \ntable with a list of people and the number of movie tickets they purchased. \nThe purchase table: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n2 \nNajil Okoro \n2 \nJohn Anderson \n1 \nQuery: \nSELECT \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nResult: \ntotal_tickets \nnumber_of_purchas",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 7,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "os \n3 \nSujin Lee \n2 \nNajil Okoro \n2 \nJohn Anderson \n1 \nQuery: \nSELECT \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nResult: \ntotal_tickets \nnumber_of_purchase \ns \n8 \n4 \n\n\n \n \n \n  ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n \n  \n ​\n​ ​\n​  \n​\n​ \n ​\n​ ​\n​  \n ​\n​ ​\n​  \n​\n​ \n ​\n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  ​\n \n​ \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \nYou can also add a DISTINCT clause inside the function. This will work for most SQL dialects but it is \nalways good to first check and confirm that the function works with the dialect that your company \nuses. Adding a DISTINCT clause in your SUM() or COUNT() function lets you do an aggregation on",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 8,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "it is \nalways good to first check and confirm that the function works with the dialect that your company \nuses. Adding a DISTINCT clause in your SUM() or COUNT() function lets you do an aggregation only on \neach distinct value of the field. Check it out in the example below: \nSELECT \nSUM(tickets) AS total_tickets, \nSUM(DISTINCT tickets) AS total_distinct_tickets, \nCOUNT(tickets) AS number_of_purchases, \nCOUNT(DISTINCT tickets) AS \nnumber_of_distinct_purchases \nFROM \npurchases \nResult: \ntotal_tickets \ntotal_distinct_tickets \nnumber_of_purchases \nnumber_of_distinct_ \npurchases \n8 \n6 \n4 \n3 \nYou might notice that the results contain smaller numbers for the columns with DISTINCT in them. That \nis because DISTINCT tells SQL to only aggregate unique values. To better understand this, check out the \nsecond column for total_distinct_tickets, which demonstrates how DISTINCT can be used with a SUM() \nfunction. But, in this example, it doesn’t really make sense to do a sum of distinct values. You will \nprobably never use DISTINCT with SUM() functions. Instead, you will more likely use DISTINCT with \nCOUNT() functions since it is helpful in identifying unique cases. \nUsing GROUP BY with aggrega",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 9,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "will \nprobably never use DISTINCT with SUM() functions. Instead, you will more likely use DISTINCT with \nCOUNT() functions since it is helpful in identifying unique cases. \nUsing GROUP BY with aggregators \nEarlier, when you learned about SUM() and COUNT() with movie ticket purchases, you summarized the \ndata to get the total number of tickets purchased and the total number of purchases made with SUM() \nand COUNT(). When you use aggregate functions like SUM() and COUNT() with a GROUP BY clause, the \ngroups are summarized in slices specified by the GROUP BY clause. \nFor example, let’s pretend that your purchase table is like the one below, where each person’s \ntransaction was for a particular occasion. You would want to use a GROUP BY clause if you want to get \nthe total number of tickets sold and the total number of purchases made by the occasion type. You will \nnotice that if you want to aggregate by something (e.g. occasion), you can use the GROUP BY clause. In \nthis way, SQL is pretty intuitive. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 10,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "y intuitive. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n   \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \nThe new purchase table: \noccasion \nname \ntickets \nfun \nRachel DeSantos \n5 \ndate \nSujin Lee \n2 \ndate \nNajil Okoro \n2 \nfun \nJohn Anderson \n3 \nQuery: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \nResults: \noccasion \ntotal_tickets \nnumber_of_purchases \nfun \n8 \n2 \ndate \n4 \n2 \nAwesome! Now you know how to use the GROUP BY clause and when you would want to use it. Here is \nanother cool thing to know: you can use the column number in the GROUP BY clause to specify what \nyou want to group by instead of using the column names. In the last example, you wanted to group by \nthe occasion. Occasion is the first column written in the SQL query. That means it is possible to write \nGROUP BY 1 instead of GROUP BY occasion. If occasion was the second column in",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 11,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "nted to group by \nthe occasion. Occasion is the first column written in the SQL query. That means it is possible to write \nGROUP BY 1 instead of GROUP BY occasion. If occasion was the second column in the SELECT clause, \nthen you would write GROUP BY 2. See below: \nQuery: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \n\n\n \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n    \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n ​\n​ \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n ​\n​ \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \nIs the same as: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \n1 \nKnowing this shortcut can save you time when writing your SQL queries and when you are grouping by \nmultiple fields. In that case, you just need to separate them with commas (e.g. GROUP BY 1, 2, 3, 4). \nWhen to use HAVING \nThe HAVING clause is similar to the WHERE cla",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 12,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "s and when you are grouping by \nmultiple fields. In that case, you just need to separate them with commas (e.g. GROUP BY 1, 2, 3, 4). \nWhen to use HAVING \nThe HAVING clause is similar to the WHERE clause since it filters the data based on certain conditions. \nBut these clauses are used in different situations. The WHERE clause is used to make filters on your \ntable, like a filter for certain date ranges or specific countries. The HAVING clause is used to make \nfilters on your aggregations and has to be paired with a GROUP BY clause. \nThe purchase table: \noccasion \nname \ntickets \nfun \nRachel DeSantos \n5 \ndate \nSujin Lee \n2 \ndate \nNajil Okoro \n2 \nfun \nJohn Anderson \n3 \nIn this example, you will notice that you can layer on the HAVING clause if you want to set limits on your \naggregation, or the sum and count in this case: \n\n\n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n  \n  ​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 13,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n \n​ \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nQuery: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \nHAVING \nSUM(tickets) > 5 \nResults: \noccasion \ntotal_tickets \nnumber_of_purchases \nfun \n8 \n2 \nIt is important to note that your results don’t contain the ‘date’ occasion anymore. That is because your \nHAVING clause filters for sums that are greater than 5. The ‘date’ occasion only had 4 total tickets, \nwhich is less than 5, so the ‘date’ occasion doesn’t show up in your results. \nGreat work! Now you know how and when to use the HAVING clause. As a data analyst, you will use a lot \nof WHERE clauses and only a few HAVING clauses. That is because of the business use case, but also \nbecause of resources, just like INNER JOIN vs. LEFT JOIN. If your query contains a HAVING clause, it will \ntake longer to run and will take more",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 14,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "s. That is because of the business use case, but also \nbecause of resources, just like INNER JOIN vs. LEFT JOIN. If your query contains a HAVING clause, it will \ntake longer to run and will take more resources because SQL needs to filter after it runs the SUM() and \nCOUNT() calculations. So, it is a good idea to try minimizing your usage of the HAVING clause whenever \npossible. But, if you do need to use HAVING, try using temporary tables. \nUsing ORDER BY to organize your results \nThe ORDER BY clause helps you organize your results. It goes at the end of the SQL query and it is the \nvery last clause to use unless you have a LIMIT clause. \nA slightly modified version of the purchase table: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n5 \nNajil Okoro \n2 \nJohn Anderson \n4 \n\n\n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n ​\n​ \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n​ ​ ​ ​\n  \n \n \nLet’s say that we wan",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 15,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n​ \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n​ ​ ​ ​\n  \n \n \nLet’s say that we want everyone in this table organized by the number of tickets they purchased from \nbiggest to smallest, or descending order. \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nResult: \nname \ntickets \nSujin Lee \n5 \nJohn Anderson \n4 \nRachel DeSantos \n3 \nNajil Okoro \n2 \nIf you want to show the person with the least amount of tickets first, you would order your results in \nASCending order. To do that in SQL, you can either use ASC or leave it blank since SQL orders columns \nin ASCending order by default. But, best practice is to write ASC or DESC so this clause is clear to \neveryone reading your query. \nWhen to use LIMIT \nThe LIMIT clause is helpful when you only want to work with a select number of rows. This is generally \nused in two situations. \nIn the first situation, let’s say that you want the top X number of cases. In the movie ticket example, let’s \nsay you only want the top 3 biggest purchases. You could use a LIMIT clause like below. \nQuery: \nSELECT \nname, \ntickets",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 16,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "y that you want the top X number of cases. In the movie ticket example, let’s \nsay you only want the top 3 biggest purchases. You could use a LIMIT clause like below. \nQuery: \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nLIMIT 3 --top 3 results only \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n​ ​\n​ ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \nResult: \nname \ntickets \nSujin Lee \n5 \nJohn Anderson \n4 \nRachel DeSantos \n3 \nIn the second situation, let’s say you want to work with your whole dataset before you write your query. \nIn that case, you would use a LIMIT clause so you don’t waste resources pulling in every single row. \nQuery: \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nLIMIT 20 --top 20 results only \nResult: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n5 \nNajil Okoro \n2 \nJohn Anderso",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 17,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "le row. \nQuery: \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nLIMIT 20 --top 20 results only \nResult: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n5 \nNajil Okoro \n2 \nJohn Anderson \n4 \nYou may have noticed that you only have four rows of data in our results even though you set a limit of \n20. That is because the purchase table only contains four rows of data. The LIMIT clause is a maximum \nnumber of rows to show, And if the purchase table contained one million rows, only 20 rows would \nshow. But, since the purchase table contains less than 20 rows, all of the data is shown. \nConditional expressions like CASE, IF, and COALESCE() \nConditional expressions like CASE statements and the COALESCE() function are used when you want \nto change how your results are presented. Though you are setting conditions in conditional \nexpressions, conditional expressions differ from the type of conditions you put in a WHERE clause. The \nconditions put in WHERE clauses apply to the entire query, while conditional expressions apply to just",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 18,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "re query, while conditional expressions apply to just \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n  ​\n​ \n ​\n \n \n \n ​\n \n \n \n ​\n​ ​\n \n \n \n \n​\n ​\n ​\n \n  \n \n \n  \n​ ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n  \n \n \nthat particular field. On top of that, you can change how your results are presented with conditional \nexpressions, which is something you can't do with WHERE statements. Let’s check out the three most \ncommon conditional expressions: CASE, IF, and COALESCE(). \nCASE statements \nCASE statements are most commonly used as labels within your dataset. You can use CASE statements \nto label rows that meet a certain condition as X and rows that meet another condition as Y. This is why \nyou will find it commonly used with aggregate functions when you want to group things by categories. \nHere is an example using a table of m",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 19,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "as X and rows that meet another condition as Y. This is why \nyou will find it commonly used with aggregate functions when you want to group things by categories. \nHere is an example using a table of movies that are playing at the local movie theater: \nThe MovieTheater table: \ngenre \nmovie_title \nhorror \nSilence of the Lambs \ncomedy \nJumanji \nfamily \nFrozen 2 \ndocumentary \n13th \nLet’s say you want to group these movies into the movies that you will watch and movies that you will \nnot watch, and count the number of movies that fall into each category. Your query would be: \nSELECT \nCASE \nWHEN genre = ‘horror’ THEN ‘will not watch’ \nELSE ‘will watch’ \nEND AS watch_category, --creating your own category \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 --when grouping by CASE, use position numbers or type \nentire CASE statement here \nResults: \nwatch_category \nnumber_of_movies \nWill not watch \n1 \nWill watch \n3 \nYou may notice that you added your own labels to the dataset, which you can do with CASE \nstatements. But keep in mind that this feature isn’t in all SQL dialects, including BigQuery. If you would",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 20,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "et, which you can do with CASE \nstatements. But keep in mind that this feature isn’t in all SQL dialects, including BigQuery. If you would \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n​ \n \n​ ​\n​ ​\n​ ​\n \n \n \n​ ​\n \n \n \n​ \n \n \n ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n   \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n ​\n​ ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n​\n​\n​  ​\n \n \n​  ​\n \n​  \n​ \n \n ​\n​ \n \n \n \n \n \n \n \n \n \n \n \nlike to learn more, please review the documentation for COUNT() or SUM() for your particular SQL \ndialect and check out how CASE statements can be used. \nThere is also another way that you can use CASE statements within BigQuery (again, this might not \napply to all SQL dialects). If your conditions are matches, like the example above, then you could write \nyour CASE statement as (compare lines 2-3): \nSELECT \nCASE genre \nWHEN ‘horror’ THEN ‘will not watch’ \nELSE ‘will watch’ \nEND AS watch_category \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 \nThis wil",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 21,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ompare lines 2-3): \nSELECT \nCASE genre \nWHEN ‘horror’ THEN ‘will not watch’ \nELSE ‘will watch’ \nEND AS watch_category \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 \nThis will produce the same results, but it is not recommended because it is limited to just matching \nconditions (e.g. genre = ‘horror’). By comparison, the earlier version with WHEN genre = ‘horror’ is \nflexible and can take other types of conditions, like greater than (>), less than (<), not equal to (<> or !=), \netc. \nIF statements \nNext up is IF statements. IF statements are similar to CASE statements, but they have one key \ndifference: CASE statements can take multiple conditions, whereas IF statements can't. In the example \nabove, you only had one condition (e.g. WHEN genre = ‘horror’), so you could have also used an IF \nstatement such as: \nSELECT \nIF(genre=’horror’, ‘will not watch’, ‘will watch’) \nAS watch_category, \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 \n\n\n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n ​\n ​ ​\n​ \n ​\n \n \n \n ​\n ​ ​\n​ \n ​\n \n \n \n ​\n \n \n \n \n ​\n \n ​\n​ \n ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n ​\n​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 22,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n ​ ​\n​ \n ​\n \n \n \n ​\n ​ ​\n​ \n ​\n \n \n \n ​\n \n \n \n \n ​\n \n ​\n​ \n ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n ​\n​ \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n   \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n   \n \n \n  \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n1 \nBut, if you have multiple conditions, you will want to use a CASE statement such as: \nSELECT \nCASE \nWHEN genre = ‘horror’ THEN ‘will not watch’ \nWHEN genre = ‘documentary’ THEN ‘will watch \nalone’ \nELSE ‘watch with others’ \nEND AS watch_category, \nCOUNT (movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \nResults: \nwatch_category \nnumber_of_movies \nWill not watch \n1 \nWill watch alone \n1 \nWatch with others \n2 \nCOALESCE() function \nFinally, there is the COALESCE() function. This function is used to return the first non-null expression in \nthe order specified in the function. It is useful when your data is spread out in multiple columns. For \nexample, let’s say you have a table of movies as rows, columns as months, and values as 1 if the movie \nlaunched in that month or null if it didn’t. See table MovieLaunches below: \nmovie_title \nJan_2030",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 23,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ple, let’s say you have a table of movies as rows, columns as months, and values as 1 if the movie \nlaunched in that month or null if it didn’t. See table MovieLaunches below: \nmovie_title \nJan_2030 \nFeb_2030 \nMar_2030 \nAvengers X \n1 \nnull \nnull \nFrozen V \nnull \n1 \nnull \nLion King IV \nnull \nnull \nnull \n\n\n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n ​\n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n   \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n  \n \n \n \n  \n  \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n ​\n​  \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n  \n  \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n   \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n    \n \n \n \n  \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \nIf you want to know if these movies have launched between Jan-Mar 2030, then you can use \nCOALESCE. For example: \nSELECT \nmovie_title, \nCOALESCE(Jan_2030, Feb_2030, Mar_2030) AS \nlaunched_indicator \nFROM \nMovieLaunches \nResults: \nmovie_title \nlaunched_indicator \nAvengers X \n1 \nFrozen V \n1 \nLion King IV \nnull \nYou may n",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 24,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "movie_title, \nCOALESCE(Jan_2030, Feb_2030, Mar_2030) AS \nlaunched_indicator \nFROM \nMovieLaunches \nResults: \nmovie_title \nlaunched_indicator \nAvengers X \n1 \nFrozen V \n1 \nLion King IV \nnull \nYou may notice that two out of the three movies had non-null values in the fields specified (Jan_2030, \nFeb_2030, Mar_2030). This example demonstrates how the COALESCE function works. It will search \nthrough each column you specify within the function and try to return a non-null value if it finds one. \nIn the workplace, COALESCE is often used to make sure that fields don’t contain nulls. So a COALESCE \nstatement could be: COALESCE(try_this_field, then_this_field, 0) to tell SQL to check the first two fields \nin order for a non-null value. If none exist in those fields, then assign a zero in place of a null. In \nBigQuery, this is the same as using the IFNULL() function (more about that here). Other SQL dialects \nmay not have the IFNULL() function, and in that case, COALESCE() is then used instead. \nCreating and deleting tables \nData in SQL is stored in tables. This guide has been referencing small tables like the purchase, \nMovieLaunches, and MovieTheater tables. These are tables that already e",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 25,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Creating and deleting tables \nData in SQL is stored in tables. This guide has been referencing small tables like the purchase, \nMovieLaunches, and MovieTheater tables. These are tables that already exist because you didn’t create \nthem. \nCreating tables \nThe ideal situation to create a table is if the following three conditions are met: \n1. \nComplex query containing multiple JOINs \n2. Result output is a table \n3. You need to run the query frequently or on a regular basis \nIf these conditions are met, then it is a great idea to create a reporting table. But it is best practice to \ncheck with your manager or teammates before you do in case you need to access permissions to \ncreate a reporting table. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n  \n \n \n   \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n  \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n \n  \n \n \n \n \n \n  \n \n \n​ \n ​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 26,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​ \n ​  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n  \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n \n  \n \n \n \n \n \n  \n \n \nThe syntax for creating tables will change depending on the SQL dialect and SQL platform you use. You \nwill go over how to create tables in BigQuery here, but if your company uses a different SQL dialect, it is \na good idea to search online for how to create tables in that SQL dialect (e.g. “Create tables in \nPostgreSQL”). Or better yet, ask your manager or teammate for help. \nGenerally speaking, when you create tables, you want to make sure the same table doesn’t already \nexist. This is because if you try to create a table that already exists, the query will return an error. \nChecking for existing tables will differ between SQL dialects, but it is always a good thing to check to \navoid unnecessary errors in your work. \nThe way to check for pre-existing tables in BigQuery is: \nCREATE TABLE IF NOT EXISTS mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmo",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 27,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "check to \navoid unnecessary errors in your work. \nThe way to check for pre-existing tables in BigQuery is: \nCREATE TABLE IF NOT EXISTS mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \nFavorite_Movies AS m ON c.friend = m.friend \nYou have already created a FavoriteColorAndMovie table! You can reference this single table to find the \nfavorite color and/or favorite movie of each friend without having to join the two separate tables, \nFavorite_Colors and Favorite_Movies, each time. \nThe CREATE TABLE IF NOT EXISTS method is best if the tables in your query (e.g. Favorite_Colors and \nFavorite_Movies) are not being continuously updated. The CREATE TABLE IF NOT EXISTS won’t do \nanything if the table already exists because it won’t be updated. So, if the source tables are \ncontinuously being updated (e.g. new friends are continuously added with their favorite colors and \nmovies), then it is better to go with a different method of creating tables. \nThis other method of creating tables is the CREATE OR REPLACE TABLE method. Here is how that \nworks: \nCREATE OR REPLACE TABLE mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor,",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 28,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ting tables. \nThis other method of creating tables is the CREATE OR REPLACE TABLE method. Here is how that \nworks: \nCREATE OR REPLACE TABLE mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \n\n\n​ \n ​  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n   \n \n \n   \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n  \n \n    \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n \n \n \n \n \n \n ​\n \n \n \n​ \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFavorite_Movies AS m ON c.friend = m.friend",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 29,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Favorite_Movies AS m ON c.friend = m.friend \nYou may notice how the only difference between the two ways of creating tables is the first line of the \nquery. This tells SQL what to do if the table already exists. CREATE TABLE IF NOT EXISTS will only create \na table if it doesn’t already exist. If it exists, then the query will run but won’t do anything. This is a \nfailsafe so that you don’t accidentally overwrite a potentially important table. Alternatively, if you do \nneed to overwrite a table, you can use CREATE OR REPLACE TABLE. \nIn summary, you would use CREATE TABLE IF NOT EXISTS if you are creating a static table that doesn’t \nneed to be updated. If your table needs to be continuously updated, you would use CREATE OR \nREPLACE TABLE instead. \nDeleting tables \nNow let’s talk about deleting tables. This rarely happens, but it is important to learn about because, \nonce the tables are deleted, the data contained in them may be lost. And, since the data is owned by \nthe company you are working for, deleting a table could mean ge",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 30,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "important to learn about because, \nonce the tables are deleted, the data contained in them may be lost. And, since the data is owned by \nthe company you are working for, deleting a table could mean getting rid of something that is not \nyours. \nThink about how you would treat a social media account that didn’t belong to you. For example, if your \ncompany gave you access to their account. You can look at the posts and maybe (with permission) \ncreate your own post for them, but you wouldn’t delete a social media post because this is the owner’s \naccount, not yours. \nIf you ever find yourself contemplating hitting the delete button for a table that you didn’t create, make \nsure you verify the reasons why you’re hitting delete and double check with your manager just in case. \nBut, if you ever need to delete a table, especially if it is one that you created and don’t need anymore, \nyou can delete a table in BigQuery by using this query: \nDROP TABLE IF EXISTS mydataset.FavoriteColorAndMovie \nDROP TABLE tells SQL to delete the table, and the IF EXISTS part makes sure that you don’t get an error \nif the table doesn’t exist. This is a failsafe, so that if the table exists, the table will be",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 31,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "DROP TABLE tells SQL to delete the table, and the IF EXISTS part makes sure that you don’t get an error \nif the table doesn’t exist. This is a failsafe, so that if the table exists, the table will be dropped. If the table \ndoesn’t exist and you run this query, then nothing will happen. So, either way, the failsafe works in your \nfavor. Best practice is to add on the IF EXISTS. \nTemporary tables \nSo far, you have learned how to create tables and when you would want to create them. Feel free to \nreview that in the above section if you ever need a refresher. The tables that you create with the \nCREATE TABLE IF NOT EXISTS method or CREATE OR REPLACE TABLE method are permanent tables. \nThey can be shared and seen by others, and they can be accessed later. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n  \n \n \n \n ​\n​ ​\n​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 32,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n​ ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n ​\n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \nBut, there might be situations where you don’t need to create permanent tables. Remember: storing \ndata in SQL costs the company money and resources. If you don’t need a permanent table, you can \ncreate temporary tables instead. Temporary tables only exist within your session (or up to 24 hours \ndepending on your SQL platform) and aren’t shareable or viewable by others. Temporary tables exist \nonly for you during your session. Think of temporary tables like a scratch pad where you can scribble \nout your calculations before putting down your final answer. \nLet’s start by outlining when you would want to create a permanent table vs. a temporary table. \nHere are the three conditions for when you would want to create a permanent table. All three \nconditions should be met. \n1. \nComplex query containing multipl",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 33,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "a permanent table vs. a temporary table. \nHere are the three conditions for when you would want to create a permanent table. All three \nconditions should be met. \n1. \nComplex query containing multiple JOINs \n2. Result output is a table \n3. You need to run the query frequently or on a regular basis \nAlternatively, Temporary tables are used to break down complex queries into smaller increments. \nThese complex queries can contain multiple JOINs but don’t necessarily have to. You might want to use \ntemporary tables if one or more of the following conditions apply: \n● \nSlowly running query with multiple JOINs and WHERE statements \n● \nSlowly running query containing GROUP BY and HAVING \n● \nNested queries (i.e. query within a query) \n● \nIf you need to do a calculation on top of a calculation (e.g. take sum per day then average \nacross the day sums) \nIf any of the above conditions are met, then using a temporary table may speed up your query, which \nwill make it easier for you to write the query, as well as make it easier for you to troubleshoot your query \nif something goes wrong. \nHere is how to create a temporary table: \nCREATE TEMP TABLE ExampleTable \nAS \nSELECT \ncolors \nFROM \nFavorit",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 34,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ery, as well as make it easier for you to troubleshoot your query \nif something goes wrong. \nHere is how to create a temporary table: \nCREATE TEMP TABLE ExampleTable \nAS \nSELECT \ncolors \nFROM \nFavorite_Colors \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n ​\n \n \n  \n \n \n \n \n \n  \n \n \n​ \n ​  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n  \n  \n ​\n​ ​\n​  \n ​\n​ ​\n \n \n \n \n \n \n  \n ​ ​  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nNow, let’s go back to the permanent table you created earlier: \nCREATE TABLE IF NOT EXISTS mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \nFavorite_Movies AS m ON c.friend = m.friend \nThis query works for a permanent table because all three of the conditions that we previously \nmentioned were met. But, for temporary tables, this query isn’t a good idea. You are working with \nmultipl",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 35,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "his query works for a permanent table because all three of the conditions that we previously \nmentioned were met. But, for temporary tables, this query isn’t a good idea. You are working with \nmultiple JOINs but there are no WHERE statements, and the query runs really quickly since the \nFavorite_Colors and Favorite_Movies tables are relatively small (<100k rows). \nLet’s consider a different scenario when you would want to use temporary tables. Earlier you learned \nabout GROUP BY and HAVING. If your query contains both clauses, such as the one below, then you \nmight want to use temporary tables if your query is running slowly. \nTemporary table query (if your query is running slowly): \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \nHAVING \nSUM(tickets) > 5 \nIn the above query, SQL has to perform three actions. First, it will group your table by occasion. Second, \nit will take the SUM() and COUNT() of the tickets column. Third, it will only show occasions with a SUM() \nof tickets that are greater than five. If the purchases table were much larger (1+ million rows) and you \nalso had JOINs in this table, the",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 36,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ets column. Third, it will only show occasions with a SUM() \nof tickets that are greater than five. If the purchases table were much larger (1+ million rows) and you \nalso had JOINs in this table, then your query would most likely run slowly. But, you can avoid this using \nthe HAVING clause and speed up your query by breaking down the query into two steps using \ntemporary tables. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n ​\n \n \n  \n  \n ​\n​ ​\n​  \n ​\n​ ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n  \n \n \n \n \n \n  ​  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n ​\n \n​ \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFirst, you can do the GROUP BY aggregations: \nCREATE TEMP TABLE TicketsByOccasion \nAS \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion; \nThen, you can do the HAVING limitation as a WHERE condition: \nSELECT \noccasion, \ntotal_tickets, \nnumber_of_purchases \nFROM \nTicketsByOccasion \nWHERE \ntotal_t",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 37,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ses \nFROM \npurchases \nGROUP BY \noccasion; \nThen, you can do the HAVING limitation as a WHERE condition: \nSELECT \noccasion, \ntotal_tickets, \nnumber_of_purchases \nFROM \nTicketsByOccasion \nWHERE \ntotal_tickets > 5 \nThere are three key things to notice here: \n1. \nIf you are running two queries at the same time, which you have to do with temporary tables \n(only available during that session), then you need a semicolon separating each query. \n2. The first query is where you created the temporary table. The second query references this \ntemporary table and its fields. That is why you can access the sum of tickets as total_tickets in \nthe second query. \n3. When creating table names, don’t use spaces or the query will return an error. Best practice is \nto use camelcase capitalization when naming the table you are building. Camelcase \ncapitalization means that you capitalize the start of each word without any spaces in between, \njust like a camel’s hump. For example, the table TicketsByOccasion uses camelcase \ncapitalization. \nIn conclusion, you don’t have to use temporary tables, but they can be a really useful tool to help break \ndown complex or complicated queries into smaller and more ma",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 38,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "uses camelcase \ncapitalization. \nIn conclusion, you don’t have to use temporary tables, but they can be a really useful tool to help break \ndown complex or complicated queries into smaller and more manageable steps. \n\n\n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \nConclusion \nThis guide covers a lot of concepts, but you can come back to it again and again as you continue to \nwrite SQL queries on your own. As you have learned throughout this course, practice is an important \npart of the learning process, and the more that you practice working in SQL, the more you will make \nnew discoveries. You can save this guide so that you can review and reference these functions and \nconcepts as needed.",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 39,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Syllabus\nIntro\nKey Concepts\nCybersecurity\nAdarsh Kumar\nProfessor, Systems, School of Computer Science, UPES, Dehradun,\nUttrakhand, India\nadarsh.kumar@ddn.upes.ac.in\nJanuary 31, 2025\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n1 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nTable of Contents\n1\nSyllabus\nUnit-I: 10 Lecture Hours\nUNIT II: 12 Lecture Hours\nUNIT III: 11 Lecture Hours\nUNIT IV: 12 Lecture Hours\n2\nIntro\n3\nKey Concepts\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n2 / 23\n\n\n[Image]: there is a man that is standing in the dark with a cell phone\n\nSyllabus\nIntro\nKey Concepts\nCourse Objectives\nTo enable the students to understand the basic concepts of\ncyber security in the connected world.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n3 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nCourse Outcomes\nCO1: Describe the fundamentals of Cyber Security.\nCO2: Analyze several types of vulnerabilities, attacks, and\ncryptography concepts.\nCO3: Apply the various approaches for information security\naudit.\nCO4: Categorize the Physical and Network vulnerabilities and\nSecurity threats.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[d",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "graphy concepts.\nCO3: Apply the various approaches for information security\naudit.\nCO4: Categorize the Physical and Network vulnerabilities and\nSecurity threats.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n4 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nTextbooks and Reference Books\nTextbooks\nBehrouz A. Forouzan and Debdeep Mukhopadhyay,\nCryptography & Network Security, Second Edition, Tata\nMcGraw Hill, New Delhi, 2010\nDouglas R. Stinson, “Cryptography: Theory and Practice”,\nThird Edition, CRC Press.\nWilliam Stallings, “Cryptography and Network Security –\nPrinciples and Practices”, Pearson Education, Fourth Edition,\n2006\nN. S. Godbole, Information Systems Security, Wiley, 2009.\nV. K. Jain, Cryptography and Network Security, Khanna\nPublishing House, 2013.\nReference Books\nP. V. K, Cryptography and Information Security, Third Edition,\nPHI Learning Pvt. Ltd., 2019.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n5 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nAssessment Weightage\nComponents\nIA\nMID SEM\nEnd Sem\nTotal\nWeightage (%)\n50\n20\n30\n100\nTable: Assessment Weightage Distribution\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanua",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "Concepts\nAssessment Weightage\nComponents\nIA\nMID SEM\nEnd Sem\nTotal\nWeightage (%)\n50\n20\n30\n100\nTable: Assessment Weightage Distribution\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n6 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nInternal Assessment Weightage\nInternal Assessment Component\nWeightage (100 marks)\nQuiz 1\n15%\nQuiz 2\n15%\nClass Test 1\n15%\nClass Test 2\n15%\nAssignment 1/Project\n20%\nAssignment 2/Project\n20%\nTable: Weightage of Internal Assessment Components\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n7 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUnit -1\nIntroduction to Cyber Space\nIntroduction to Information Systems\nNeed for Cyber Security\nIntroduction to Cyber Attacks\nClassification of Cyber Attacks\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n8 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUnit-II: Malware and Security Tools\nClassification of Malware\nThreats\nExplanation of Malware\nTypes of Malware:\nVirus\nWorms\nTrojans\nRootkits\nRobots\nAdware\nSpyware\nRansomware\nZombies\nMalware Analysis\nOpen Source Tools:\nAntivirus Protection\nAnti-Spyware\nSystem Tuning Tools\nAnti-Phishing\nVulnerability Assessment\nIntrusion Detect",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "jans\nRootkits\nRobots\nAdware\nSpyware\nRansomware\nZombies\nMalware Analysis\nOpen Source Tools:\nAntivirus Protection\nAnti-Spyware\nSystem Tuning Tools\nAnti-Phishing\nVulnerability Assessment\nIntrusion Detection Systems (IDS)\nIntrusion Prevention Systems (IPS)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n9 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUNIT III:Cryptography and Cryptanalysis\nIntroduction to Cryptography\nSymmetric Key Cryptography\nAsymmetric Key Cryptography\nMessage Authentication\nDigital Signatures\nApplications of Cryptography\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n10 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUNIT IV: Cyber Law-Basics\nInformation Technology Act 2000\nAmendments to IT Act 2000\nEvidentiary Value of Email/SMS\nCybercrimes and Offenses Dealt with IPC\nRBI Act and IPR Act in India\nJurisdiction of Cyber Crime\nCyber Security Awareness Tips\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n11 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nWelcome to the Basics!\nDiscover the fundamental concepts and key principles.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n12 / 23\n\n\nSy",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "23\n\n\nSyllabus\nIntro\nKey Concepts\nWelcome to the Basics!\nDiscover the fundamental concepts and key principles.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n12 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nIntroduction\nDefinition of Cybersecurity\nImportance of Cybersecurity\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n13 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nIntroduction to Cybersecurity\nDefinition of Cybersecurity\nCybersecurity refers to the practice of protecting systems,\nnetworks, and data from digital attacks, unauthorized access,\nand damage. It involves implementing various technologies,\nprocesses, and practices to safeguard information and ensure\nthe integrity, confidentiality, and availability of digital assets.\nImportance of Cybersecurity\nProtection of Sensitive Data: Safeguards personal, financial, and\nsensitive information from breaches and theft.\nPrevention of Cyber Attacks: Shields against various types of cyber\nthreats such as malware, ransomware, and phishing.\nMaintaining Trust and Reputation: Ensures that organizations and\nindividuals maintain trust and a positive reputation by protecting against\ndata breaches and secu",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "as malware, ransomware, and phishing.\nMaintaining Trust and Reputation: Ensures that organizations and\nindividuals maintain trust and a positive reputation by protecting against\ndata breaches and security incidents.\nCompliance with Regulations: Helps organizations adhere to regulatory\nrequirements and standards related to data protection and privacy.\nEnsuring Business Continuity: Minimizes disruptions and potential\nfinancial losses by preventing and mitigating the impact of cyber incidents.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n14 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nCybersecurity and Cyberspace\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n15 / 23\n\n\n[Image]: a diagram of the integration of a data system\n\nSyllabus\nIntro\nKey Concepts\nCybersecurity\nDefenses\nAntivirus\nAwareness Training\nEncryption\nPatch Management\nThreats\nMalware\nPhishing\nMan-in-the-Middle\nZero-Day Attacks\nCyberspace\nDevices\nPeople\nNetworks\nSoftware\nEndpoints\nSocial Engineering\nData Transmission\nExploits\nHosts\nUsers\nInfrastructure\nApplications\nTargets\nWeakest Link\nCommunication\nVulnerabilities\nAttacks\nThreats\nRisks\nExploits\nMitigation\nMitigation\nMitig",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "ints\nSocial Engineering\nData Transmission\nExploits\nHosts\nUsers\nInfrastructure\nApplications\nTargets\nWeakest Link\nCommunication\nVulnerabilities\nAttacks\nThreats\nRisks\nExploits\nMitigation\nMitigation\nMitigation\nMitigation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n16 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nCybersecurity in Healthcare\nDefenses\nEndpoint Protection\nFirewalls\nAccess Control and Authentication\nEncryption for Data at Rest and in Transit\nIncident Response Plans\nThreats\nMalware - such as Ransomware\nPhishing Attacks\nData Breaches\nUnauthorized Access\nDenial of Service - DoS\nHealthcare Cyberspace\nMedical Devices\nHealthcare Networks\nElectronic Health Records\nHealthcare Professionals\nPatient Data\nDevice Security\nNetwork Security\nApplication Security\nUser Education and Training\nData Encryption and Privacy\nProtection\nProtection\nProtection\nAwareness\nProtection\nMitigated by\nMitigated by\nMitigated by\nMitigated by\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n17 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nKey Concepts\nConfidentiality\nIntegrity\nAvailability\nAuthentication\nNon-\nrepudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]a",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "ac[dot]in\nJanuary 31, 2025\n17 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nKey Concepts\nConfidentiality\nIntegrity\nAvailability\nAuthentication\nNon-\nrepudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n18 / 23\n\n\n[Image]: a diagram of a cube with a block labeled in the middle\n\nSyllabus\nIntro\nKey Concepts\nConfidentiality\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n19 / 23\n\n\n[Image]: a diagram of a computer system with multiple components\n\nSyllabus\nIntro\nKey Concepts\nIntegrity\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n20 / 23\n\n\n[Image]: a diagram of a process of executing a data flow\n\nSyllabus\nIntro\nKey Concepts\nAvailability\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n21 / 23\n\n\n[Image]: a diagram of a process for a service management system\n\nSyllabus\nIntro\nKey Concepts\nAuthentication\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n22 / 23\n\n\n[Image]: a diagram of a process for a project\n\nSyllabus\nIntro\nKey Concepts\nNon-Repudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n23 / 23\n\n\n[Image]: a diagram",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 7,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "3\n\n\n[Image]: a diagram of a process for a project\n\nSyllabus\nIntro\nKey Concepts\nNon-Repudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n23 / 23\n\n\n[Image]: a diagram of a process of a service management system",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 8,
    "timestamp": "2025-11-17_00-11-49"
  }
]