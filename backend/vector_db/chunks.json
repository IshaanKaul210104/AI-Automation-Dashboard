[
  {
    "text": "​\n \n​ \n ​\n \n ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n  \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nYour Intermediate Guide to SQL \nAs you get more comfortable with SQL, you will be able to take on even more advanced queries. This \nin-depth guide will give you a more detailed introduction to some of the SQL functions you have \nalready learned, and give you some new tools to work with. Be sure to save this guide, so you can easily \nreference these helpful tips in the future. \nSQL Structure for More Complex Queries \nYou will learn more about these clauses and expressions in the sections below, but first let’s check out \nhow you might structure a more involved SQL query: \nSELECT \nColumn you want to look at \nFROM \nTable the da",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "rn more about these clauses and expressions in the sections below, but first let’s check out \nhow you might structure a more involved SQL query: \nSELECT \nColumn you want to look at \nFROM \nTable the data lives in \nWHERE \nCertain condition on the data \nGROUP BY \nColumn you want to aggregate by \nHAVING \nCertain condition on the aggregation \nORDER BY \nColumn you want to order results by \nand in ASCending or DESCending order \nLIMIT \nThe maximum number of rows you want \nyour results to contain \nDifferent types of JOINs \nMost analysts will use either INNER JOINs or LEFT JOINs throughout their career. When you join \ntables, you are combining data from one table with data in another table connected by a common field. \nFor example, let’s say you have your friends’ favorite colors in one table and your friends’ favorite \nmovies in another table. You can have both of their favorite colors and movies in one table by joining \nthe two tables on your friends’ names, which is the field they have in common. This is your JOIN field. In \nthe workplace, a JOIN field is usually some sort of ID, like a customer_id or account_id. \nTable view \nFavorite_Colors \nFavorite_Movies \nfriend (string) \nfriend (stri",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "mon. This is your JOIN field. In \nthe workplace, a JOIN field is usually some sort of ID, like a customer_id or account_id. \nTable view \nFavorite_Colors \nFavorite_Movies \nfriend (string) \nfriend (string) \ncolor (string) \nmovie (string) \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n​\n​\n \n \n​\n​\n​\n​\n \n \n \n \n \n \nData view \nFavorite_Colors \nfriend \ncolor \nRachel DeSantos \nblue \nSujin Lee \ngreen \nNajil Okoro \nred \nJohn Anderson \norange \nFavorite_Movies \nfriend \nmovie \nRachel DeSantos \nAvengers \nSujin Lee \nDespicable Me \nNajil Okoro \nFrozen \nSo, in this example, you would want to use an INNER JOIN if you only want to see information for friends \nwho have both a favorite color and a favorite movie. That means if John Anderson has a favorite color \nbut no favorite movie, John Anderson won’t show up in your results. Friends have to be in both tables to \nshow up in your results. So INNER JOINs are useful when you want to see data where the JOIN key \nexis",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "favorite movie, John Anderson won’t show up in your results. Friends have to be in both tables to \nshow up in your results. So INNER JOINs are useful when you want to see data where the JOIN key \nexists in both tables, which is usually why you want to join datasets in the first place. Typically, analysts \nwill use INNER JOINs most of the time. \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \nFavorite_Movies AS m ON c.friend = m.friend \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n  \n  \n  \n ​\n​   \n \n  \n ​\n​  ​\n​ \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nResults: \nfriend \ncolor \nmovie \nRachel DeSantos \nblue \nAvengers \nSujin Lee \ngreen \nDespicable Me \nNajil Okoro \nr",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Results: \nfriend \ncolor \nmovie \nRachel DeSantos \nblue \nAvengers \nSujin Lee \ngreen \nDespicable Me \nNajil Okoro \nred \nFrozen \nSince this query used an INNER JOIN, the results only have three out of the four friends. As a quick \nreminder, that is because INNER JOIN queries only return results where the JOIN field—in this case \n“friend”—exists in both tables. Since John Anderson doesn’t exist in the favorite movies table, he is \nexcluded from the query results. \nNow, let’s say you want to use a LEFT JOIN to get information for all of your friends into one table (e.g. \nfavorite colors table) with data added from the other table (e.g. favorite movies table) if it exists. So, if \nJohn Anderson has a favorite color but no favorite movie, he will still show up in your results. He will just \nhave an empty field (which is null) for his favorite movie. Most of the time LEFT JOINs are used if the \ndata you are trying to pull in from another table is optional. This is a nice-to-have field but not necessary \nfor your analysis since you may get nulls. On the job, you will find that analysts will use LEFT JOINs",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "rying to pull in from another table is optional. This is a nice-to-have field but not necessary \nfor your analysis since you may get nulls. On the job, you will find that analysts will use LEFT JOINs less \noften than INNER JOINs. \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nLEFT JOIN \nFavorite_Movies AS m ON c.friend = m.friend \nResults: \nfriend \ncolor \nmovie \nRachel DeSantos \nblue \nAvengers \nSujin Lee \ngreen \nDespicable Me \nNajil Okoro \nred \nFrozen \nJohn Anderson \norange \nnull \nSo now you know the difference between INNER JOINs and LEFT JOINs. You know that INNER JOINs \nwill be the most commonly used JOIN types because they usually align with business use cases. \nAnother reason that INNER JOINs are used is because they result in less data since the JOIN key must \nexist in both tables. This means that queries with INNER JOINs tend to run faster and use less resources \n\n\n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n ​\n​ \n ​\n​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n​ \n ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n \n \n \n \n \nthan queries with LEFT JOINs. This might not be a problem for most analysts, but if you are working with \nvery large tables that have 1+ million rows and/or depending on the SQL dialect used, your query might \ntake a lot longer to run if you use a LEFT JOIN instead of an INNER JOIN. \nBasically, the takeaway here is to use INNER JOINs as much as you can. \nAggregators like SUM() and COUNT() \nAggregators summarize rows into a single value. The functions SUM() and COUNT() are examples of \naggregators. The types of aggregators that will be available for you will depend on the SQL dialect that \nyour company uses. But the most commonly used aggregators like SUM(), COUNT(), MAX(), and MIN() \nare available in all SQL",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ggregators that will be available for you will depend on the SQL dialect that \nyour company uses. But the most commonly used aggregators like SUM(), COUNT(), MAX(), and MIN() \nare available in all SQL dialects, even if there are some slight differences. It is easy to check how \naggregators are formatted for whatever dialect you are working with. There are a lot of resources \navailable online. Just open up your favorite search engine and search for the aggregate function that \nyou want to use and your SQL dialect. For example, search for “SUM function in SQL Server.” \nAggregators all work the same way, so let’s go over SUM() and COUNT(). The SUM() function takes a \nsum of whatever column you put inside the parentheses. The COUNT() function counts the number of \nentries in whatever column you put inside the parentheses. For example, let’s say you have a purchase \ntable with a list of people and the number of movie tickets they purchased. \nThe purchase table: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n2 \nNajil Okoro \n2 \nJohn Anderson \n1 \nQuery: \nSELECT \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nResult: \ntotal_tickets \nnumber_of_purchas",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 7,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "os \n3 \nSujin Lee \n2 \nNajil Okoro \n2 \nJohn Anderson \n1 \nQuery: \nSELECT \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nResult: \ntotal_tickets \nnumber_of_purchase \ns \n8 \n4 \n\n\n \n \n \n  ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n \n  \n ​\n​ ​\n​  \n​\n​ \n ​\n​ ​\n​  \n ​\n​ ​\n​  \n​\n​ \n ​\n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  ​\n \n​ \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \nYou can also add a DISTINCT clause inside the function. This will work for most SQL dialects but it is \nalways good to first check and confirm that the function works with the dialect that your company \nuses. Adding a DISTINCT clause in your SUM() or COUNT() function lets you do an aggregation on",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 8,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "it is \nalways good to first check and confirm that the function works with the dialect that your company \nuses. Adding a DISTINCT clause in your SUM() or COUNT() function lets you do an aggregation only on \neach distinct value of the field. Check it out in the example below: \nSELECT \nSUM(tickets) AS total_tickets, \nSUM(DISTINCT tickets) AS total_distinct_tickets, \nCOUNT(tickets) AS number_of_purchases, \nCOUNT(DISTINCT tickets) AS \nnumber_of_distinct_purchases \nFROM \npurchases \nResult: \ntotal_tickets \ntotal_distinct_tickets \nnumber_of_purchases \nnumber_of_distinct_ \npurchases \n8 \n6 \n4 \n3 \nYou might notice that the results contain smaller numbers for the columns with DISTINCT in them. That \nis because DISTINCT tells SQL to only aggregate unique values. To better understand this, check out the \nsecond column for total_distinct_tickets, which demonstrates how DISTINCT can be used with a SUM() \nfunction. But, in this example, it doesn’t really make sense to do a sum of distinct values. You will \nprobably never use DISTINCT with SUM() functions. Instead, you will more likely use DISTINCT with \nCOUNT() functions since it is helpful in identifying unique cases. \nUsing GROUP BY with aggrega",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 9,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "will \nprobably never use DISTINCT with SUM() functions. Instead, you will more likely use DISTINCT with \nCOUNT() functions since it is helpful in identifying unique cases. \nUsing GROUP BY with aggregators \nEarlier, when you learned about SUM() and COUNT() with movie ticket purchases, you summarized the \ndata to get the total number of tickets purchased and the total number of purchases made with SUM() \nand COUNT(). When you use aggregate functions like SUM() and COUNT() with a GROUP BY clause, the \ngroups are summarized in slices specified by the GROUP BY clause. \nFor example, let’s pretend that your purchase table is like the one below, where each person’s \ntransaction was for a particular occasion. You would want to use a GROUP BY clause if you want to get \nthe total number of tickets sold and the total number of purchases made by the occasion type. You will \nnotice that if you want to aggregate by something (e.g. occasion), you can use the GROUP BY clause. In \nthis way, SQL is pretty intuitive. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 10,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "y intuitive. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n   \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \nThe new purchase table: \noccasion \nname \ntickets \nfun \nRachel DeSantos \n5 \ndate \nSujin Lee \n2 \ndate \nNajil Okoro \n2 \nfun \nJohn Anderson \n3 \nQuery: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \nResults: \noccasion \ntotal_tickets \nnumber_of_purchases \nfun \n8 \n2 \ndate \n4 \n2 \nAwesome! Now you know how to use the GROUP BY clause and when you would want to use it. Here is \nanother cool thing to know: you can use the column number in the GROUP BY clause to specify what \nyou want to group by instead of using the column names. In the last example, you wanted to group by \nthe occasion. Occasion is the first column written in the SQL query. That means it is possible to write \nGROUP BY 1 instead of GROUP BY occasion. If occasion was the second column in",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 11,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "nted to group by \nthe occasion. Occasion is the first column written in the SQL query. That means it is possible to write \nGROUP BY 1 instead of GROUP BY occasion. If occasion was the second column in the SELECT clause, \nthen you would write GROUP BY 2. See below: \nQuery: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \n\n\n \n \n \n \n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n    \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n ​\n​ \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n ​\n​ \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \nIs the same as: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \n1 \nKnowing this shortcut can save you time when writing your SQL queries and when you are grouping by \nmultiple fields. In that case, you just need to separate them with commas (e.g. GROUP BY 1, 2, 3, 4). \nWhen to use HAVING \nThe HAVING clause is similar to the WHERE cla",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 12,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "s and when you are grouping by \nmultiple fields. In that case, you just need to separate them with commas (e.g. GROUP BY 1, 2, 3, 4). \nWhen to use HAVING \nThe HAVING clause is similar to the WHERE clause since it filters the data based on certain conditions. \nBut these clauses are used in different situations. The WHERE clause is used to make filters on your \ntable, like a filter for certain date ranges or specific countries. The HAVING clause is used to make \nfilters on your aggregations and has to be paired with a GROUP BY clause. \nThe purchase table: \noccasion \nname \ntickets \nfun \nRachel DeSantos \n5 \ndate \nSujin Lee \n2 \ndate \nNajil Okoro \n2 \nfun \nJohn Anderson \n3 \nIn this example, you will notice that you can layer on the HAVING clause if you want to set limits on your \naggregation, or the sum and count in this case: \n\n\n \n  \n \n ​\n​ ​\n​  \n ​\n​ ​\n \n  \n \n \n \n \n  \n  ​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 13,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n \n​ \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nQuery: \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \nHAVING \nSUM(tickets) > 5 \nResults: \noccasion \ntotal_tickets \nnumber_of_purchases \nfun \n8 \n2 \nIt is important to note that your results don’t contain the ‘date’ occasion anymore. That is because your \nHAVING clause filters for sums that are greater than 5. The ‘date’ occasion only had 4 total tickets, \nwhich is less than 5, so the ‘date’ occasion doesn’t show up in your results. \nGreat work! Now you know how and when to use the HAVING clause. As a data analyst, you will use a lot \nof WHERE clauses and only a few HAVING clauses. That is because of the business use case, but also \nbecause of resources, just like INNER JOIN vs. LEFT JOIN. If your query contains a HAVING clause, it will \ntake longer to run and will take more",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 14,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "s. That is because of the business use case, but also \nbecause of resources, just like INNER JOIN vs. LEFT JOIN. If your query contains a HAVING clause, it will \ntake longer to run and will take more resources because SQL needs to filter after it runs the SUM() and \nCOUNT() calculations. So, it is a good idea to try minimizing your usage of the HAVING clause whenever \npossible. But, if you do need to use HAVING, try using temporary tables. \nUsing ORDER BY to organize your results \nThe ORDER BY clause helps you organize your results. It goes at the end of the SQL query and it is the \nvery last clause to use unless you have a LIMIT clause. \nA slightly modified version of the purchase table: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n5 \nNajil Okoro \n2 \nJohn Anderson \n4 \n\n\n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n ​\n​ \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n​ ​ ​ ​\n  \n \n \nLet’s say that we wan",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 15,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n​ \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n​ ​ ​ ​\n  \n \n \nLet’s say that we want everyone in this table organized by the number of tickets they purchased from \nbiggest to smallest, or descending order. \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nResult: \nname \ntickets \nSujin Lee \n5 \nJohn Anderson \n4 \nRachel DeSantos \n3 \nNajil Okoro \n2 \nIf you want to show the person with the least amount of tickets first, you would order your results in \nASCending order. To do that in SQL, you can either use ASC or leave it blank since SQL orders columns \nin ASCending order by default. But, best practice is to write ASC or DESC so this clause is clear to \neveryone reading your query. \nWhen to use LIMIT \nThe LIMIT clause is helpful when you only want to work with a select number of rows. This is generally \nused in two situations. \nIn the first situation, let’s say that you want the top X number of cases. In the movie ticket example, let’s \nsay you only want the top 3 biggest purchases. You could use a LIMIT clause like below. \nQuery: \nSELECT \nname, \ntickets",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 16,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "y that you want the top X number of cases. In the movie ticket example, let’s \nsay you only want the top 3 biggest purchases. You could use a LIMIT clause like below. \nQuery: \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nLIMIT 3 --top 3 results only \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n​ ​\n​ ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \nResult: \nname \ntickets \nSujin Lee \n5 \nJohn Anderson \n4 \nRachel DeSantos \n3 \nIn the second situation, let’s say you want to work with your whole dataset before you write your query. \nIn that case, you would use a LIMIT clause so you don’t waste resources pulling in every single row. \nQuery: \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nLIMIT 20 --top 20 results only \nResult: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n5 \nNajil Okoro \n2 \nJohn Anderso",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 17,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "le row. \nQuery: \nSELECT \nname, \ntickets \nFROM \npurchases \nORDER BY \ntickets DESC \nLIMIT 20 --top 20 results only \nResult: \nname \ntickets \nRachel DeSantos \n3 \nSujin Lee \n5 \nNajil Okoro \n2 \nJohn Anderson \n4 \nYou may have noticed that you only have four rows of data in our results even though you set a limit of \n20. That is because the purchase table only contains four rows of data. The LIMIT clause is a maximum \nnumber of rows to show, And if the purchase table contained one million rows, only 20 rows would \nshow. But, since the purchase table contains less than 20 rows, all of the data is shown. \nConditional expressions like CASE, IF, and COALESCE() \nConditional expressions like CASE statements and the COALESCE() function are used when you want \nto change how your results are presented. Though you are setting conditions in conditional \nexpressions, conditional expressions differ from the type of conditions you put in a WHERE clause. The \nconditions put in WHERE clauses apply to the entire query, while conditional expressions apply to just",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 18,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "re query, while conditional expressions apply to just \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n  ​\n​ \n ​\n \n \n \n ​\n \n \n \n ​\n​ ​\n \n \n \n \n​\n ​\n ​\n \n  \n \n \n  \n​ ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n  \n \n \nthat particular field. On top of that, you can change how your results are presented with conditional \nexpressions, which is something you can't do with WHERE statements. Let’s check out the three most \ncommon conditional expressions: CASE, IF, and COALESCE(). \nCASE statements \nCASE statements are most commonly used as labels within your dataset. You can use CASE statements \nto label rows that meet a certain condition as X and rows that meet another condition as Y. This is why \nyou will find it commonly used with aggregate functions when you want to group things by categories. \nHere is an example using a table of m",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 19,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "as X and rows that meet another condition as Y. This is why \nyou will find it commonly used with aggregate functions when you want to group things by categories. \nHere is an example using a table of movies that are playing at the local movie theater: \nThe MovieTheater table: \ngenre \nmovie_title \nhorror \nSilence of the Lambs \ncomedy \nJumanji \nfamily \nFrozen 2 \ndocumentary \n13th \nLet’s say you want to group these movies into the movies that you will watch and movies that you will \nnot watch, and count the number of movies that fall into each category. Your query would be: \nSELECT \nCASE \nWHEN genre = ‘horror’ THEN ‘will not watch’ \nELSE ‘will watch’ \nEND AS watch_category, --creating your own category \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 --when grouping by CASE, use position numbers or type \nentire CASE statement here \nResults: \nwatch_category \nnumber_of_movies \nWill not watch \n1 \nWill watch \n3 \nYou may notice that you added your own labels to the dataset, which you can do with CASE \nstatements. But keep in mind that this feature isn’t in all SQL dialects, including BigQuery. If you would",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 20,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "et, which you can do with CASE \nstatements. But keep in mind that this feature isn’t in all SQL dialects, including BigQuery. If you would \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n​ \n \n​ ​\n​ ​\n​ ​\n \n \n \n​ ​\n \n \n \n​ \n \n \n ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n   \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n ​\n​ ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n​\n​\n​  ​\n \n \n​  ​\n \n​  \n​ \n \n ​\n​ \n \n \n \n \n \n \n \n \n \n \n \nlike to learn more, please review the documentation for COUNT() or SUM() for your particular SQL \ndialect and check out how CASE statements can be used. \nThere is also another way that you can use CASE statements within BigQuery (again, this might not \napply to all SQL dialects). If your conditions are matches, like the example above, then you could write \nyour CASE statement as (compare lines 2-3): \nSELECT \nCASE genre \nWHEN ‘horror’ THEN ‘will not watch’ \nELSE ‘will watch’ \nEND AS watch_category \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 \nThis wil",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 21,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ompare lines 2-3): \nSELECT \nCASE genre \nWHEN ‘horror’ THEN ‘will not watch’ \nELSE ‘will watch’ \nEND AS watch_category \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 \nThis will produce the same results, but it is not recommended because it is limited to just matching \nconditions (e.g. genre = ‘horror’). By comparison, the earlier version with WHEN genre = ‘horror’ is \nflexible and can take other types of conditions, like greater than (>), less than (<), not equal to (<> or !=), \netc. \nIF statements \nNext up is IF statements. IF statements are similar to CASE statements, but they have one key \ndifference: CASE statements can take multiple conditions, whereas IF statements can't. In the example \nabove, you only had one condition (e.g. WHEN genre = ‘horror’), so you could have also used an IF \nstatement such as: \nSELECT \nIF(genre=’horror’, ‘will not watch’, ‘will watch’) \nAS watch_category, \nCOUNT(movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \n1 \n\n\n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n ​\n ​ ​\n​ \n ​\n \n \n \n ​\n ​ ​\n​ \n ​\n \n \n \n ​\n \n \n \n \n ​\n \n ​\n​ \n ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n ​\n​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 22,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n ​ ​\n​ \n ​\n \n \n \n ​\n ​ ​\n​ \n ​\n \n \n \n ​\n \n \n \n \n ​\n \n ​\n​ \n ​\n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n ​\n​ \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n   \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n   \n \n \n  \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n1 \nBut, if you have multiple conditions, you will want to use a CASE statement such as: \nSELECT \nCASE \nWHEN genre = ‘horror’ THEN ‘will not watch’ \nWHEN genre = ‘documentary’ THEN ‘will watch \nalone’ \nELSE ‘watch with others’ \nEND AS watch_category, \nCOUNT (movie_title) AS number_of_movies \nFROM \nMovieTheater \nGROUP BY \nResults: \nwatch_category \nnumber_of_movies \nWill not watch \n1 \nWill watch alone \n1 \nWatch with others \n2 \nCOALESCE() function \nFinally, there is the COALESCE() function. This function is used to return the first non-null expression in \nthe order specified in the function. It is useful when your data is spread out in multiple columns. For \nexample, let’s say you have a table of movies as rows, columns as months, and values as 1 if the movie \nlaunched in that month or null if it didn’t. See table MovieLaunches below: \nmovie_title \nJan_2030",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 23,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ple, let’s say you have a table of movies as rows, columns as months, and values as 1 if the movie \nlaunched in that month or null if it didn’t. See table MovieLaunches below: \nmovie_title \nJan_2030 \nFeb_2030 \nMar_2030 \nAvengers X \n1 \nnull \nnull \nFrozen V \nnull \n1 \nnull \nLion King IV \nnull \nnull \nnull \n\n\n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n ​\n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n   \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n  \n \n \n \n  \n  \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n ​\n​  \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n  \n  \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n   \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n    \n \n \n \n  \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \nIf you want to know if these movies have launched between Jan-Mar 2030, then you can use \nCOALESCE. For example: \nSELECT \nmovie_title, \nCOALESCE(Jan_2030, Feb_2030, Mar_2030) AS \nlaunched_indicator \nFROM \nMovieLaunches \nResults: \nmovie_title \nlaunched_indicator \nAvengers X \n1 \nFrozen V \n1 \nLion King IV \nnull \nYou may n",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 24,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "movie_title, \nCOALESCE(Jan_2030, Feb_2030, Mar_2030) AS \nlaunched_indicator \nFROM \nMovieLaunches \nResults: \nmovie_title \nlaunched_indicator \nAvengers X \n1 \nFrozen V \n1 \nLion King IV \nnull \nYou may notice that two out of the three movies had non-null values in the fields specified (Jan_2030, \nFeb_2030, Mar_2030). This example demonstrates how the COALESCE function works. It will search \nthrough each column you specify within the function and try to return a non-null value if it finds one. \nIn the workplace, COALESCE is often used to make sure that fields don’t contain nulls. So a COALESCE \nstatement could be: COALESCE(try_this_field, then_this_field, 0) to tell SQL to check the first two fields \nin order for a non-null value. If none exist in those fields, then assign a zero in place of a null. In \nBigQuery, this is the same as using the IFNULL() function (more about that here). Other SQL dialects \nmay not have the IFNULL() function, and in that case, COALESCE() is then used instead. \nCreating and deleting tables \nData in SQL is stored in tables. This guide has been referencing small tables like the purchase, \nMovieLaunches, and MovieTheater tables. These are tables that already e",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 25,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Creating and deleting tables \nData in SQL is stored in tables. This guide has been referencing small tables like the purchase, \nMovieLaunches, and MovieTheater tables. These are tables that already exist because you didn’t create \nthem. \nCreating tables \nThe ideal situation to create a table is if the following three conditions are met: \n1. \nComplex query containing multiple JOINs \n2. Result output is a table \n3. You need to run the query frequently or on a regular basis \nIf these conditions are met, then it is a great idea to create a reporting table. But it is best practice to \ncheck with your manager or teammates before you do in case you need to access permissions to \ncreate a reporting table. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n  \n \n \n   \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n  \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n \n  \n \n \n \n \n \n  \n \n \n​ \n ​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 26,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​ \n ​  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n  \n  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n ​\n \n \n  \n \n \n \n \n \n  \n \n \nThe syntax for creating tables will change depending on the SQL dialect and SQL platform you use. You \nwill go over how to create tables in BigQuery here, but if your company uses a different SQL dialect, it is \na good idea to search online for how to create tables in that SQL dialect (e.g. “Create tables in \nPostgreSQL”). Or better yet, ask your manager or teammate for help. \nGenerally speaking, when you create tables, you want to make sure the same table doesn’t already \nexist. This is because if you try to create a table that already exists, the query will return an error. \nChecking for existing tables will differ between SQL dialects, but it is always a good thing to check to \navoid unnecessary errors in your work. \nThe way to check for pre-existing tables in BigQuery is: \nCREATE TABLE IF NOT EXISTS mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmo",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 27,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "check to \navoid unnecessary errors in your work. \nThe way to check for pre-existing tables in BigQuery is: \nCREATE TABLE IF NOT EXISTS mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \nFavorite_Movies AS m ON c.friend = m.friend \nYou have already created a FavoriteColorAndMovie table! You can reference this single table to find the \nfavorite color and/or favorite movie of each friend without having to join the two separate tables, \nFavorite_Colors and Favorite_Movies, each time. \nThe CREATE TABLE IF NOT EXISTS method is best if the tables in your query (e.g. Favorite_Colors and \nFavorite_Movies) are not being continuously updated. The CREATE TABLE IF NOT EXISTS won’t do \nanything if the table already exists because it won’t be updated. So, if the source tables are \ncontinuously being updated (e.g. new friends are continuously added with their favorite colors and \nmovies), then it is better to go with a different method of creating tables. \nThis other method of creating tables is the CREATE OR REPLACE TABLE method. Here is how that \nworks: \nCREATE OR REPLACE TABLE mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor,",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 28,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ting tables. \nThis other method of creating tables is the CREATE OR REPLACE TABLE method. Here is how that \nworks: \nCREATE OR REPLACE TABLE mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \n\n\n​ \n ​  \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n   \n \n \n   \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n  \n \n    \n \n \n \n \n \n \n \n \n \n \n  \n  \n \n \n \n \n \n \n \n \n \n ​\n \n \n \n​ \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFavorite_Movies AS m ON c.friend = m.friend",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 29,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Favorite_Movies AS m ON c.friend = m.friend \nYou may notice how the only difference between the two ways of creating tables is the first line of the \nquery. This tells SQL what to do if the table already exists. CREATE TABLE IF NOT EXISTS will only create \na table if it doesn’t already exist. If it exists, then the query will run but won’t do anything. This is a \nfailsafe so that you don’t accidentally overwrite a potentially important table. Alternatively, if you do \nneed to overwrite a table, you can use CREATE OR REPLACE TABLE. \nIn summary, you would use CREATE TABLE IF NOT EXISTS if you are creating a static table that doesn’t \nneed to be updated. If your table needs to be continuously updated, you would use CREATE OR \nREPLACE TABLE instead. \nDeleting tables \nNow let’s talk about deleting tables. This rarely happens, but it is important to learn about because, \nonce the tables are deleted, the data contained in them may be lost. And, since the data is owned by \nthe company you are working for, deleting a table could mean ge",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 30,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "important to learn about because, \nonce the tables are deleted, the data contained in them may be lost. And, since the data is owned by \nthe company you are working for, deleting a table could mean getting rid of something that is not \nyours. \nThink about how you would treat a social media account that didn’t belong to you. For example, if your \ncompany gave you access to their account. You can look at the posts and maybe (with permission) \ncreate your own post for them, but you wouldn’t delete a social media post because this is the owner’s \naccount, not yours. \nIf you ever find yourself contemplating hitting the delete button for a table that you didn’t create, make \nsure you verify the reasons why you’re hitting delete and double check with your manager just in case. \nBut, if you ever need to delete a table, especially if it is one that you created and don’t need anymore, \nyou can delete a table in BigQuery by using this query: \nDROP TABLE IF EXISTS mydataset.FavoriteColorAndMovie \nDROP TABLE tells SQL to delete the table, and the IF EXISTS part makes sure that you don’t get an error \nif the table doesn’t exist. This is a failsafe, so that if the table exists, the table will be",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 31,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "DROP TABLE tells SQL to delete the table, and the IF EXISTS part makes sure that you don’t get an error \nif the table doesn’t exist. This is a failsafe, so that if the table exists, the table will be dropped. If the table \ndoesn’t exist and you run this query, then nothing will happen. So, either way, the failsafe works in your \nfavor. Best practice is to add on the IF EXISTS. \nTemporary tables \nSo far, you have learned how to create tables and when you would want to create them. Feel free to \nreview that in the above section if you ever need a refresher. The tables that you create with the \nCREATE TABLE IF NOT EXISTS method or CREATE OR REPLACE TABLE method are permanent tables. \nThey can be shared and seen by others, and they can be accessed later. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n \n \n \n \n \n \n \n \n \n  \n \n \n \n ​\n​ ​\n​",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 32,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "​\n​ ​\n​ \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n ​\n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \nBut, there might be situations where you don’t need to create permanent tables. Remember: storing \ndata in SQL costs the company money and resources. If you don’t need a permanent table, you can \ncreate temporary tables instead. Temporary tables only exist within your session (or up to 24 hours \ndepending on your SQL platform) and aren’t shareable or viewable by others. Temporary tables exist \nonly for you during your session. Think of temporary tables like a scratch pad where you can scribble \nout your calculations before putting down your final answer. \nLet’s start by outlining when you would want to create a permanent table vs. a temporary table. \nHere are the three conditions for when you would want to create a permanent table. All three \nconditions should be met. \n1. \nComplex query containing multipl",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 33,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "a permanent table vs. a temporary table. \nHere are the three conditions for when you would want to create a permanent table. All three \nconditions should be met. \n1. \nComplex query containing multiple JOINs \n2. Result output is a table \n3. You need to run the query frequently or on a regular basis \nAlternatively, Temporary tables are used to break down complex queries into smaller increments. \nThese complex queries can contain multiple JOINs but don’t necessarily have to. You might want to use \ntemporary tables if one or more of the following conditions apply: \n● \nSlowly running query with multiple JOINs and WHERE statements \n● \nSlowly running query containing GROUP BY and HAVING \n● \nNested queries (i.e. query within a query) \n● \nIf you need to do a calculation on top of a calculation (e.g. take sum per day then average \nacross the day sums) \nIf any of the above conditions are met, then using a temporary table may speed up your query, which \nwill make it easier for you to write the query, as well as make it easier for you to troubleshoot your query \nif something goes wrong. \nHere is how to create a temporary table: \nCREATE TEMP TABLE ExampleTable \nAS \nSELECT \ncolors \nFROM \nFavorit",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 34,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ery, as well as make it easier for you to troubleshoot your query \nif something goes wrong. \nHere is how to create a temporary table: \nCREATE TEMP TABLE ExampleTable \nAS \nSELECT \ncolors \nFROM \nFavorite_Colors \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n ​\n \n \n  \n \n \n \n \n \n  \n \n \n​ \n ​  \n \n  \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n  \n  \n ​\n​ ​\n​  \n ​\n​ ​\n \n \n \n \n \n \n  \n ​ ​  \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n  \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nNow, let’s go back to the permanent table you created earlier: \nCREATE TABLE IF NOT EXISTS mydataset.FavoriteColorAndMovie \nAS \nSELECT \nfriend, \ncolor, \nmovie \nFROM \nFavorite_Colors AS c \nINNER JOIN \nFavorite_Movies AS m ON c.friend = m.friend \nThis query works for a permanent table because all three of the conditions that we previously \nmentioned were met. But, for temporary tables, this query isn’t a good idea. You are working with \nmultipl",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 35,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "his query works for a permanent table because all three of the conditions that we previously \nmentioned were met. But, for temporary tables, this query isn’t a good idea. You are working with \nmultiple JOINs but there are no WHERE statements, and the query runs really quickly since the \nFavorite_Colors and Favorite_Movies tables are relatively small (<100k rows). \nLet’s consider a different scenario when you would want to use temporary tables. Earlier you learned \nabout GROUP BY and HAVING. If your query contains both clauses, such as the one below, then you \nmight want to use temporary tables if your query is running slowly. \nTemporary table query (if your query is running slowly): \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion \nHAVING \nSUM(tickets) > 5 \nIn the above query, SQL has to perform three actions. First, it will group your table by occasion. Second, \nit will take the SUM() and COUNT() of the tickets column. Third, it will only show occasions with a SUM() \nof tickets that are greater than five. If the purchases table were much larger (1+ million rows) and you \nalso had JOINs in this table, the",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 36,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ets column. Third, it will only show occasions with a SUM() \nof tickets that are greater than five. If the purchases table were much larger (1+ million rows) and you \nalso had JOINs in this table, then your query would most likely run slowly. But, you can avoid this using \nthe HAVING clause and speed up your query by breaking down the query into two steps using \ntemporary tables. \n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n ​\n \n \n  \n  \n ​\n​ ​\n​  \n ​\n​ ​\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n  \n \n \n \n \n \n  ​  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n ​\n \n​ \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFirst, you can do the GROUP BY aggregations: \nCREATE TEMP TABLE TicketsByOccasion \nAS \nSELECT \noccasion, \nSUM(tickets) AS total_tickets, \nCOUNT(tickets) AS number_of_purchases \nFROM \npurchases \nGROUP BY \noccasion; \nThen, you can do the HAVING limitation as a WHERE condition: \nSELECT \noccasion, \ntotal_tickets, \nnumber_of_purchases \nFROM \nTicketsByOccasion \nWHERE \ntotal_t",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 37,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "ses \nFROM \npurchases \nGROUP BY \noccasion; \nThen, you can do the HAVING limitation as a WHERE condition: \nSELECT \noccasion, \ntotal_tickets, \nnumber_of_purchases \nFROM \nTicketsByOccasion \nWHERE \ntotal_tickets > 5 \nThere are three key things to notice here: \n1. \nIf you are running two queries at the same time, which you have to do with temporary tables \n(only available during that session), then you need a semicolon separating each query. \n2. The first query is where you created the temporary table. The second query references this \ntemporary table and its fields. That is why you can access the sum of tickets as total_tickets in \nthe second query. \n3. When creating table names, don’t use spaces or the query will return an error. Best practice is \nto use camelcase capitalization when naming the table you are building. Camelcase \ncapitalization means that you capitalize the start of each word without any spaces in between, \njust like a camel’s hump. For example, the table TicketsByOccasion uses camelcase \ncapitalization. \nIn conclusion, you don’t have to use temporary tables, but they can be a really useful tool to help break \ndown complex or complicated queries into smaller and more ma",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 38,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "uses camelcase \ncapitalization. \nIn conclusion, you don’t have to use temporary tables, but they can be a really useful tool to help break \ndown complex or complicated queries into smaller and more manageable steps. \n\n\n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \nConclusion \nThis guide covers a lot of concepts, but you can come back to it again and again as you continue to \nwrite SQL queries on your own. As you have learned throughout this course, practice is an important \npart of the learning process, and the more that you practice working in SQL, the more you will make \nnew discoveries. You can save this guide so that you can review and reference these functions and \nconcepts as needed.",
    "source_file": "2025-11-16_17-57-07_SQL GUIDE.pdf",
    "chunk_index": 39,
    "timestamp": "2025-11-16_18-44-45"
  },
  {
    "text": "Syllabus\nIntro\nKey Concepts\nCybersecurity\nAdarsh Kumar\nProfessor, Systems, School of Computer Science, UPES, Dehradun,\nUttrakhand, India\nadarsh.kumar@ddn.upes.ac.in\nJanuary 31, 2025\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n1 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nTable of Contents\n1\nSyllabus\nUnit-I: 10 Lecture Hours\nUNIT II: 12 Lecture Hours\nUNIT III: 11 Lecture Hours\nUNIT IV: 12 Lecture Hours\n2\nIntro\n3\nKey Concepts\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n2 / 23\n\n\n[Image]: there is a man that is standing in the dark with a cell phone\n\nSyllabus\nIntro\nKey Concepts\nCourse Objectives\nTo enable the students to understand the basic concepts of\ncyber security in the connected world.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n3 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nCourse Outcomes\nCO1: Describe the fundamentals of Cyber Security.\nCO2: Analyze several types of vulnerabilities, attacks, and\ncryptography concepts.\nCO3: Apply the various approaches for information security\naudit.\nCO4: Categorize the Physical and Network vulnerabilities and\nSecurity threats.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[d",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "graphy concepts.\nCO3: Apply the various approaches for information security\naudit.\nCO4: Categorize the Physical and Network vulnerabilities and\nSecurity threats.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n4 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nTextbooks and Reference Books\nTextbooks\nBehrouz A. Forouzan and Debdeep Mukhopadhyay,\nCryptography & Network Security, Second Edition, Tata\nMcGraw Hill, New Delhi, 2010\nDouglas R. Stinson, “Cryptography: Theory and Practice”,\nThird Edition, CRC Press.\nWilliam Stallings, “Cryptography and Network Security –\nPrinciples and Practices”, Pearson Education, Fourth Edition,\n2006\nN. S. Godbole, Information Systems Security, Wiley, 2009.\nV. K. Jain, Cryptography and Network Security, Khanna\nPublishing House, 2013.\nReference Books\nP. V. K, Cryptography and Information Security, Third Edition,\nPHI Learning Pvt. Ltd., 2019.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n5 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nAssessment Weightage\nComponents\nIA\nMID SEM\nEnd Sem\nTotal\nWeightage (%)\n50\n20\n30\n100\nTable: Assessment Weightage Distribution\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanua",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "Concepts\nAssessment Weightage\nComponents\nIA\nMID SEM\nEnd Sem\nTotal\nWeightage (%)\n50\n20\n30\n100\nTable: Assessment Weightage Distribution\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n6 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nInternal Assessment Weightage\nInternal Assessment Component\nWeightage (100 marks)\nQuiz 1\n15%\nQuiz 2\n15%\nClass Test 1\n15%\nClass Test 2\n15%\nAssignment 1/Project\n20%\nAssignment 2/Project\n20%\nTable: Weightage of Internal Assessment Components\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n7 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUnit -1\nIntroduction to Cyber Space\nIntroduction to Information Systems\nNeed for Cyber Security\nIntroduction to Cyber Attacks\nClassification of Cyber Attacks\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n8 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUnit-II: Malware and Security Tools\nClassification of Malware\nThreats\nExplanation of Malware\nTypes of Malware:\nVirus\nWorms\nTrojans\nRootkits\nRobots\nAdware\nSpyware\nRansomware\nZombies\nMalware Analysis\nOpen Source Tools:\nAntivirus Protection\nAnti-Spyware\nSystem Tuning Tools\nAnti-Phishing\nVulnerability Assessment\nIntrusion Detect",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "jans\nRootkits\nRobots\nAdware\nSpyware\nRansomware\nZombies\nMalware Analysis\nOpen Source Tools:\nAntivirus Protection\nAnti-Spyware\nSystem Tuning Tools\nAnti-Phishing\nVulnerability Assessment\nIntrusion Detection Systems (IDS)\nIntrusion Prevention Systems (IPS)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n9 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUNIT III:Cryptography and Cryptanalysis\nIntroduction to Cryptography\nSymmetric Key Cryptography\nAsymmetric Key Cryptography\nMessage Authentication\nDigital Signatures\nApplications of Cryptography\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n10 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nUNIT IV: Cyber Law-Basics\nInformation Technology Act 2000\nAmendments to IT Act 2000\nEvidentiary Value of Email/SMS\nCybercrimes and Offenses Dealt with IPC\nRBI Act and IPR Act in India\nJurisdiction of Cyber Crime\nCyber Security Awareness Tips\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n11 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nWelcome to the Basics!\nDiscover the fundamental concepts and key principles.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n12 / 23\n\n\nSy",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "23\n\n\nSyllabus\nIntro\nKey Concepts\nWelcome to the Basics!\nDiscover the fundamental concepts and key principles.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n12 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nIntroduction\nDefinition of Cybersecurity\nImportance of Cybersecurity\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n13 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nIntroduction to Cybersecurity\nDefinition of Cybersecurity\nCybersecurity refers to the practice of protecting systems,\nnetworks, and data from digital attacks, unauthorized access,\nand damage. It involves implementing various technologies,\nprocesses, and practices to safeguard information and ensure\nthe integrity, confidentiality, and availability of digital assets.\nImportance of Cybersecurity\nProtection of Sensitive Data: Safeguards personal, financial, and\nsensitive information from breaches and theft.\nPrevention of Cyber Attacks: Shields against various types of cyber\nthreats such as malware, ransomware, and phishing.\nMaintaining Trust and Reputation: Ensures that organizations and\nindividuals maintain trust and a positive reputation by protecting against\ndata breaches and secu",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "as malware, ransomware, and phishing.\nMaintaining Trust and Reputation: Ensures that organizations and\nindividuals maintain trust and a positive reputation by protecting against\ndata breaches and security incidents.\nCompliance with Regulations: Helps organizations adhere to regulatory\nrequirements and standards related to data protection and privacy.\nEnsuring Business Continuity: Minimizes disruptions and potential\nfinancial losses by preventing and mitigating the impact of cyber incidents.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n14 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nCybersecurity and Cyberspace\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n15 / 23\n\n\n[Image]: a diagram of the integration of a data system\n\nSyllabus\nIntro\nKey Concepts\nCybersecurity\nDefenses\nAntivirus\nAwareness Training\nEncryption\nPatch Management\nThreats\nMalware\nPhishing\nMan-in-the-Middle\nZero-Day Attacks\nCyberspace\nDevices\nPeople\nNetworks\nSoftware\nEndpoints\nSocial Engineering\nData Transmission\nExploits\nHosts\nUsers\nInfrastructure\nApplications\nTargets\nWeakest Link\nCommunication\nVulnerabilities\nAttacks\nThreats\nRisks\nExploits\nMitigation\nMitigation\nMitig",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "ints\nSocial Engineering\nData Transmission\nExploits\nHosts\nUsers\nInfrastructure\nApplications\nTargets\nWeakest Link\nCommunication\nVulnerabilities\nAttacks\nThreats\nRisks\nExploits\nMitigation\nMitigation\nMitigation\nMitigation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n16 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nCybersecurity in Healthcare\nDefenses\nEndpoint Protection\nFirewalls\nAccess Control and Authentication\nEncryption for Data at Rest and in Transit\nIncident Response Plans\nThreats\nMalware - such as Ransomware\nPhishing Attacks\nData Breaches\nUnauthorized Access\nDenial of Service - DoS\nHealthcare Cyberspace\nMedical Devices\nHealthcare Networks\nElectronic Health Records\nHealthcare Professionals\nPatient Data\nDevice Security\nNetwork Security\nApplication Security\nUser Education and Training\nData Encryption and Privacy\nProtection\nProtection\nProtection\nAwareness\nProtection\nMitigated by\nMitigated by\nMitigated by\nMitigated by\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n17 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nKey Concepts\nConfidentiality\nIntegrity\nAvailability\nAuthentication\nNon-\nrepudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]a",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "ac[dot]in\nJanuary 31, 2025\n17 / 23\n\n\nSyllabus\nIntro\nKey Concepts\nKey Concepts\nConfidentiality\nIntegrity\nAvailability\nAuthentication\nNon-\nrepudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n18 / 23\n\n\n[Image]: a diagram of a cube with a block labeled in the middle\n\nSyllabus\nIntro\nKey Concepts\nConfidentiality\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n19 / 23\n\n\n[Image]: a diagram of a computer system with multiple components\n\nSyllabus\nIntro\nKey Concepts\nIntegrity\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n20 / 23\n\n\n[Image]: a diagram of a process of executing a data flow\n\nSyllabus\nIntro\nKey Concepts\nAvailability\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n21 / 23\n\n\n[Image]: a diagram of a process for a service management system\n\nSyllabus\nIntro\nKey Concepts\nAuthentication\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n22 / 23\n\n\n[Image]: a diagram of a process for a project\n\nSyllabus\nIntro\nKey Concepts\nNon-Repudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n23 / 23\n\n\n[Image]: a diagram",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 7,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "3\n\n\n[Image]: a diagram of a process for a project\n\nSyllabus\nIntro\nKey Concepts\nNon-Repudiation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n23 / 23\n\n\n[Image]: a diagram of a process of a service management system",
    "source_file": "2025-11-17_00-11-49_1A.pdf",
    "chunk_index": 8,
    "timestamp": "2025-11-17_00-11-49"
  },
  {
    "text": "Phishing Attack\nDoS Attack\nCybersecurity\nAdarsh Kumar\nProfessor, Systems, School of Computer Science, UPES, Dehradun,\nUttrakhand, India\nadarsh.kumar@ddn.upes.ac.in\nJanuary 31, 2025\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n1 / 25\n\n\nPhishing Attack\nDoS Attack\nTable of Contents\n1\nPhishing Attack\n2\nDoS Attack\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n2 / 25\n\n\n[Image]: there is a man that is standing in the dark with a cell phone\n\nPhishing Attack\nDoS Attack\nPhishing\nPhishing is a type of social engineering attack where attackers\ndeceive individuals into providing sensitive information such as\nusernames, passwords, or credit card numbers. Phishing typically\noccurs via:\nEmail: Fake emails that appear to be from legitimate sources requesting\npersonal information.\nWebsites: Fraudulent websites are designed to look like legitimate sites to steal\nuser credentials.\nMessages: Text messages or social media messages that trick individuals into\nrevealing personal information.\nAttacker\nVictim\nPhishing Email\nFake Website\nSensitive Information\nSends Phishing Email\nDelivers Phishing Email\nClicks Link in Email\nDisplays Fake Login Pa",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "ividuals into\nrevealing personal information.\nAttacker\nVictim\nPhishing Email\nFake Website\nSensitive Information\nSends Phishing Email\nDelivers Phishing Email\nClicks Link in Email\nDisplays Fake Login Page\nEnters Sensitive Information\nSends Collected Information\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n3 / 25\n\n\nPhishing Attack\nDoS Attack\nTypes of Phishing and Their Properties\nType of Phishing\nDescription\nCommon Indicators\nEmail Phishing\nUses fraudulent emails that appear to come\nfrom a legitimate source to trick users into\nrevealing sensitive information.\nSuspicious sender address, urgent language,\nunexpected attachments or links.\nSpear Phishing\nTargets specific individuals or organizations\nwith personalized emails to increase the like-\nlihood of success.\nPersonalization of email content, often con-\ntains specific details about the target.\nWhaling\nA type of spear phishing targeting high-\nprofile individuals such as executives or im-\nportant figures within an organization.\nHigh level of personalization, often involves\nhigh-value targets or sensitive topics.\nSmishing\nPhishing conducted via SMS or text mes-\nsages. Often includes a link to a fake websit",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "in an organization.\nHigh level of personalization, often involves\nhigh-value targets or sensitive topics.\nSmishing\nPhishing conducted via SMS or text mes-\nsages. Often includes a link to a fake website\nor requests personal information directly.\nUnexpected text messages, urgent requests\nfor personal information, suspicious links.\nVishing\nVoice phishing carried out over phone calls,\nwhere attackers impersonate legitimate or-\nganizations to extract sensitive information.\nUnsolicited calls, requests for personal infor-\nmation, pressure to act quickly.\nClone Phishing\nInvolves creating a nearly identical replica\nof a legitimate email that has been previ-\nously sent, but with malicious links or at-\ntachments.\nIdentical design to a legitimate email, but\nwith altered or new malicious content.\nTable: Different Types of Phishing and Their Properties\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n4 / 25\n\n\nPhishing Attack\nDoS Attack\nEmail Phishing Diagram\nAttacker\nCrafts Phishing Email\nSends Email to Victim\nVictim Receives Email\nClicks Malicious Link\nFake Website\nAttacker Collects Data\nDescription\nEmail Phishing:\nUses fraudulent emails that appear to come from a le",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "ts Phishing Email\nSends Email to Victim\nVictim Receives Email\nClicks Malicious Link\nFake Website\nAttacker Collects Data\nDescription\nEmail Phishing:\nUses fraudulent emails that appear to come from a legitimate source to trick users into revealing\nsensitive information.\nCommon Indicators:\nSuspicious sender address\nUrgent language\nUnexpected attachments or links\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n5 / 25\n\n\nPhishing Attack\nDoS Attack\nSpear Phishing Diagram\nFigure: Diagram illustrating a\nphishing attack.\nDescription\nSpear Phishing:\nTargets specific individuals or organizations with\npersonalized messages to increase the likelihood of\nsuccess.\nTypical Steps:\nResearch Target: The attacker gathers\ninformation about the target to make the\nphishing attempt more convincing.\nCrafts Personalized Email: The attacker\ncreates an email that appears to come from\na trusted source, using information gathered\nabout the target.\nSends Email to Target: The attacker sends\nthe personalized email to the target.\nClicks Malicious Link: The target clicks on\na link within the email that directs to a\nfraudulent website.\nFake Website: The website collects\nsensitive informati",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "s\nthe personalized email to the target.\nClicks Malicious Link: The target clicks on\na link within the email that directs to a\nfraudulent website.\nFake Website: The website collects\nsensitive information from the target.\nAttacker Collects Data: The attacker\ngathers the information entered by the\ntarget on the fake website.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n6 / 25\n\n\n[Image]: diagram of a computer attacker and its steps\n\nPhishing Attack\nDoS Attack\nPhising Detection Process\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n7 / 25\n\n\n[Image]: a diagram of a process of sending email to a person\n\nPhishing Attack\nDoS Attack\nWhat is Link or Attachment Metadata?\nMetadata refers to information that describes or provides\ndetails about other data.\nFor links:\nDomain name (e.g., ‘example.com‘)\nURL length (e.g., ‘https://short.ly/abc‘)\nPresence of special characters (‘\nSSL/TLS status (e.g., ‘https://‘ vs ‘http://‘)\nFor attachments:\nFile type (e.g., ‘.exe‘, ‘.pdf‘, ‘.docx‘)\nFile size and hash (e.g., ‘SHA-256‘ checksum)\nEmbedded scripts or macros\nEmail headers (e.g., MIME type)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[d",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "ile type (e.g., ‘.exe‘, ‘.pdf‘, ‘.docx‘)\nFile size and hash (e.g., ‘SHA-256‘ checksum)\nEmbedded scripts or macros\nEmail headers (e.g., MIME type)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n8 / 25\n\n\nPhishing Attack\nDoS Attack\nHow Metadata Helps in Phishing Detection\nExample: Analyzing Links\nCheck if the domain matches trusted sources:\n‘https://www.bankofamerica.com‘ (safe)\n‘https://bankofamerica-secure-login.com‘ (suspicious)\nValidate SSL/TLS certificates for legitimacy.\nLook for URL obfuscation:\n‘http://tinyurl.com/abc123‘ →Resolve to destination\nbefore clicking.\nExample: Analyzing Attachments\nFlag suspicious file types:\n‘.exe‘, ‘.js‘, ‘.vbs‘ (commonly used in phishing attacks).\nCompare file hashes with known malware databases.\nAnalyze macros in documents for malicious intent.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n9 / 25\n\n\nPhishing Attack\nDoS Attack\nPhishing Detection Tools\nBrowser-based Tools\nGoogle Safe Browsing\nMicrosoft SmartScreen\nFirefox Phishing and Malware Protection\nEmail Security Tools\nProofpoint\nMimecast\nBarracuda Email Security\nSpamTitan\nPhishER (KnowBe4)\nAnti-phishing Software\nNorton 360\nAvast Ant",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "Microsoft SmartScreen\nFirefox Phishing and Malware Protection\nEmail Security Tools\nProofpoint\nMimecast\nBarracuda Email Security\nSpamTitan\nPhishER (KnowBe4)\nAnti-phishing Software\nNorton 360\nAvast Anti-Phishing\nKaspersky Internet Security\nMcAfee Total Protection\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n10 / 25\n\n\nPhishing Attack\nDoS Attack\nPhishing Detection Tools (Continued)\nURL Scanners\nVirusTotal\nPhishtank\nURLScan.io\nBrowser Extensions\nNetcraft Anti-Phishing Extension\nAvira Browser Safety\nOnline Tools\nCheckPhish\nScamadviser\nZscaler Cloud Security\nEnterprise-grade Security Platforms\nCisco Secure Email\nSymantec Email Security\nIBM Trusteer\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n11 / 25\n\n\nPhishing Attack\nDoS Attack\nPhishing Detection Tools (Continued)\nAwareness and Training Tools\nKnowBe4\nCofense PhishMe\nWombat Security\nDomain Monitoring Tools\nBrandShield\nBolster\nRiskIQ\nAI and Machine Learning Tools\nPhish.AI\nArea 1 Security\nOpenPhish\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n12 / 25\n\n\nPhishing Attack\nDoS Attack\nDenial of Service (DoS) Attacks\nA Denial of Service (DoS) attack ai",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "Security\nOpenPhish\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n12 / 25\n\n\nPhishing Attack\nDoS Attack\nDenial of Service (DoS) Attacks\nA Denial of Service (DoS) attack aims to make a network service,\nserver, or website unavailable to users by overwhelming it with a\nflood of illegitimate requests. Variants include:\nSYN Flood: Exploits the TCP handshake process to overload\nservers.\nUDP Flood: Sends a large number of UDP packets to\nrandom ports, causing a system to exhaust resources.\nHTTP Flood: Targets web servers by sending a large volume\nof HTTP requests.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n13 / 25\n\n\nPhishing Attack\nDoS Attack\nDoS\nAttacker\nDoS\nFlood\nNetworkServer\nInitiates Attack\nSends Flood of Requests\nOverwhelms Network/Server\nNo Response (Outage)\nFigure: Diagram illustrating a phishing attack.\nDenial of Service (DoS) Attack:\nAims to make a service, network, or system unavailable by overwhelming it with a flood of\nillegitimate requests.\nTypical Methods:\nFlood Attack: Sends a massive volume of traffic to exhaust the system’s resources,\ncausing service disruption.\nPing of Death: Sends oversized or malformed pack",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 7,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "illegitimate requests.\nTypical Methods:\nFlood Attack: Sends a massive volume of traffic to exhaust the system’s resources,\ncausing service disruption.\nPing of Death: Sends oversized or malformed packets to crash or freeze the target system.\nSYN Flood: Exploits the TCP handshake process by sending numerous connection\nrequests without completing them, exhausting server resources.\nDistributed Denial of Service (DDoS): Utilizes multiple compromised systems to generate\na coordinated flood of traffic, amplifying the attack’s impact.\nApplication Layer Attack: Targets specific applications by sending requests that consume\nexcessive resources or exploit vulnerabilities.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n14 / 25\n\n\nPhishing Attack\nDoS Attack\nDoS Attack Types\nVolume-Based Attacks\nProtocol Attacks\nApplication Layer Attacks\nDistributed Denial of Service (DDoS) Attacks\nResource Exhaustion Attacks\nAmplification Attacks\nZero-Day Attacks\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n15 / 25\n\n\nPhishing Attack\nDoS Attack\nVolume-Based Attacks\nUDP Flood: Sends a large number of UDP packets to random ports, consuming\nresources.\nIC",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 8,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "t]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n15 / 25\n\n\nPhishing Attack\nDoS Attack\nVolume-Based Attacks\nUDP Flood: Sends a large number of UDP packets to random ports, consuming\nresources.\nICMP Flood: Sends a flood of ICMP Echo Request packets to overwhelm the\ntarget.\nICMP (Internet Control Message Protocol) packets are crucial for network operations\nand diagnostics.\nMajor Operations: Error Reporting, Network Diagnostics, Flow Control, and Network\nManagement.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n16 / 25\n\n\n[Image]: a diagram of a computer network with multiple computers and a number of different computers\n\nPhishing Attack\nDoS Attack\nProtocol Attacks\nSYN Flood: Exploits TCP handshake by sending SYN\nrequests without completing the handshake.\nPing of Death: Sends maliciously crafted ping packets that\noverflow memory buffers.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n17 / 25\n\n\nPhishing Attack\nDoS Attack\nApplication Layer Attacks\nHTTP Flood: Sends a large number of HTTP requests to\nexhaust server resources.\nSlowloris: Holds connections open with partial HTTP\nheaders, consuming server resources.\nAdarsh Kum",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 9,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "ication Layer Attacks\nHTTP Flood: Sends a large number of HTTP requests to\nexhaust server resources.\nSlowloris: Holds connections open with partial HTTP\nheaders, consuming server resources.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n18 / 25\n\n\nPhishing Attack\nDoS Attack\nDistributed Denial of Service (DDoS) Attacks\nBotnet-Based Attacks: Uses a network of compromised\ndevices to launch coordinated attacks.\nFigure: Diagram illustrating Botnet-based attacks\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n19 / 25\n\n\n[Image]: a diagram of a computer and a laptop connected to a network\n\nPhishing Attack\nDoS Attack\nResource Exhaustion Attacks\nMemory Flood: Overloads the target’s memory with\nexcessive data.\nCPU Flood: Consumes CPU resources with complex or\ncomputationally intensive requests.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n20 / 25\n\n\nPhishing Attack\nDoS Attack\nAmplification Attacks\nDNS Amplification: Uses open DNS resolvers to flood the\ntarget with large responses.\nNTP Amplification: Uses NTP servers to generate high\nvolumes of traffic.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 10,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "cation: Uses open DNS resolvers to flood the\ntarget with large responses.\nNTP Amplification: Uses NTP servers to generate high\nvolumes of traffic.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n21 / 25\n\n\nPhishing Attack\nDoS Attack\nZero-Day Attacks\nExploit Unknown Vulnerabilities: Uses unknown or\nunpatched vulnerabilities to launch attacks.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n22 / 25\n\n\nPhishing Attack\nDoS Attack\nMan-in-the-Middle (MitM) Attacks\nIn a Man-in-the-Middle attack, an attacker intercepts and\npotentially alters communication between two parties without their\nknowledge. Common techniques include:\nEavesdropping: Intercepting communications to gain\ninformation.\nSession Hijacking: Taking over a web session to impersonate\nthe user.\nSSL Stripping: Downgrading a secure HTTPS connection to\nan unencrypted HTTP connection to intercept data.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n23 / 25\n\n\nPhishing Attack\nDoS Attack\nInsider Threats\nInsider threats involve malicious or negligent actions by individuals\nwithin an organization that compromise security. These threats\ncan come from:",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 11,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "3 / 25\n\n\nPhishing Attack\nDoS Attack\nInsider Threats\nInsider threats involve malicious or negligent actions by individuals\nwithin an organization that compromise security. These threats\ncan come from:\nDisgruntled Employees: Individuals who intentionally cause\nharm to the organization.\nNegligent Employees: Individuals who unintentionally\nexpose the organization to risks through careless actions.\nCompromised Accounts: Employee accounts that have been\nhacked and used to access sensitive information.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n24 / 25\n\n\nPhishing Attack\nDoS Attack\nQuestions\nAny Questions?\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nJanuary 31, 2025\n25 / 25",
    "source_file": "2025-11-18_19-15-02_1C.pdf",
    "chunk_index": 12,
    "timestamp": "2025-11-18_19-15-02"
  },
  {
    "text": "WORMS\nUNIT II: Malware and Vulnerability\nAdarsh Kumar\nProfessor, Systems, School of Computer Science, UPES, Dehradun,\nUttarakhand, India\nadarsh.kumar@ddn.upes.ac.in\nSeptember 5, 2024\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n1 / 93\n\n\nTable of Contents\n1\nWorms\nIntroduction\nWorm’ Characteristics\nWorm Propagation Process\nPrevention and Protection Against Worms\nDetection and Prevention Algorithms\nSignature-Based Prevention Algorithm\nBehavioral Prevention Algorithm\nNetwork-Based Prevention\nPatch Management\nAccess Control\nNetwork Segmentation\nLeast Privilege Principle\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n2 / 93\n\n\n[Image]: there is a man that is standing in the dark with a cell phone\n\nImpact of Worms\nNetwork Disruption\nWorms can cause severe network slowdowns and outages by generating excessive traffic as they spread.\nData Loss and Theft\nSome worms carry payloads that steal sensitive information, delete files, or encrypt data, leading to data breaches and\nloss.\nEconomic Impact\nBusinesses can suffer financial losses due to downtime, data recovery costs, and damage to reputation caused by worm\ninfections.\nSystem In",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "rypt data, leading to data breaches and\nloss.\nEconomic Impact\nBusinesses can suffer financial losses due to downtime, data recovery costs, and damage to reputation caused by worm\ninfections.\nSystem Instability\nWorms can consume system resources, leading to crashes and reduced performance of infected computers.\nFormation of Botnets\nSome worms turn infected computers into bots (zombies) that can be controlled remotely by cybercriminals for further\nmalicious activities, such as sending spam or launching distributed denial-of-service (DDoS) attacks.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n3 / 93\n\n\nCharacteristics of Worms\nSelf-replicating\nWorms have the ability to make copies of themselves without any human interaction. This allows them to spread rapidly across\nnetworks.\nStandalone\nUnlike viruses, worms do not need a host program to attach themselves to. They can operate and propagate independently.\nNetwork Spreading\nWorms are designed to exploit network vulnerabilities to spread to other connected systems. They often use the infected\ncomputer’s network resources to find new targets.\nPayload Delivery\nSome worms carry a malicious payload (additional",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "rk vulnerabilities to spread to other connected systems. They often use the infected\ncomputer’s network resources to find new targets.\nPayload Delivery\nSome worms carry a malicious payload (additional malware), such as ransomware, keyloggers, or backdoors, which can perform\nharmful activities on the infected system.\nResource Consumption\nWorms can consume a significant amount of network bandwidth and system resources as they spread, leading to network\nslowdowns and system instability.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n4 / 93\n\n\nHow Worms Spread\nEmail Attachments\nWorms can spread via email by tricking users into opening malicious attachments or clicking on harmful links.\nNetwork Exploits\nWorms often exploit vulnerabilities in network services or software. For example, they may exploit open ports, unpatched\noperating systems, or vulnerabilities in network protocols to spread.\nFile Sharing\nWorms can spread through shared network drives, USB drives, or peer-to-peer file-sharing networks.\nInstant Messaging and Social Media\nWorms can use instant messaging applications or social media platforms to send malicious links to contacts.\nInternet Downloa",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": ", or peer-to-peer file-sharing networks.\nInstant Messaging and Social Media\nWorms can use instant messaging applications or social media platforms to send malicious links to contacts.\nInternet Downloads\nMalicious websites or compromised legitimate websites can host worm malware, which infects systems when users visit or\ndownload content.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n5 / 93\n\n\nNotable Examples of Worms (1/2)\nMorris Worm (1988)\nOne of the first worms to gain widespread attention, it exploited vulnerabilities in Unix systems\nand caused significant disruption on the early internet.\nILOVEYOU Worm (2000)\nSpread through email with a subject line ”ILOVEYOU,” tricking users into opening a malicious\nattachment. It caused widespread damage by overwriting files and sending itself to contacts.\nCode Red (2001)\nExploited a vulnerability in Microsoft’s IIS web server to infect and deface websites, leading to\nsignificant server downtime.\nSlammer Worm (2003)\nSpread rapidly by exploiting a vulnerability in Microsoft’s SQL Server, causing network\ncongestion and denial of service.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 20",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "3)\nSpread rapidly by exploiting a vulnerability in Microsoft’s SQL Server, causing network\ncongestion and denial of service.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n6 / 93\n\n\nNotable Examples of Worms (2/2)\nConficker (2008)\nExploited Windows vulnerabilities, creating a botnet that affected millions\nof computers worldwide. It had the capability to disable security features\nand download additional malware.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n7 / 93\n\n\nWorm Propagation Process\n1. Find New Targets\nIP random scanning\n2. Compromise Targets\nExploit vulnerability\nTrick users to run malicious code (e.g., Spam)\n3. Newly Infected Join Infection Army\nInfected systems contribute to further spread of the worm\nFind New Targets\nCompromise Targets\nNewly Infected Join Infection Army\nIP random scanning\nExploit vulnerability\nTrick users to run malicious code\nInfected systems contribute to further spread of the worm\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n8 / 93\n\n\nImpact of Worms\nNetwork Disruption\nWorms can cause severe network slowdowns and outages by generating excessive traffic as the",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "Adarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n8 / 93\n\n\nImpact of Worms\nNetwork Disruption\nWorms can cause severe network slowdowns and outages by generating excessive traffic as they spread.\nData Loss and Theft\nSome worms carry payloads that steal sensitive information, delete files, or encrypt data, leading to data breaches and loss.\nEconomic Impact\nBusinesses can suffer financial losses due to downtime, data recovery costs, and damage to reputation caused by worm infections.\nSystem Instability\nWorms can consume system resources, leading to crashes and reduced performance of infected computers.\nFormation of Botnets\nSome worms turn infected computers into bots (zombies) that can be controlled remotely by cybercriminals for further malicious\nactivities, such as sending spam or launching distributed denial-of-service (DDoS) attacks.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n9 / 93\n\n\nPrevention and Protection Against Worms (1/2)\nRegular Software Updates\nKeep operating systems, software, and applications up to date with the latest security patches to protect against known\nvulnerabilities.\nUse Antivirus and Antimalware Software\nInst",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ar Software Updates\nKeep operating systems, software, and applications up to date with the latest security patches to protect against known\nvulnerabilities.\nUse Antivirus and Antimalware Software\nInstall and regularly update reputable antivirus and antimalware software to detect and remove worms.\nFirewalls\nUse network and host-based firewalls to block unauthorized access and monitor suspicious network activity.\nUser Education\nEducate users about the dangers of opening email attachments or clicking on links from unknown or untrusted sources.\nNetwork Segmentation\nIsolate critical systems and data from the rest of the network to minimize the spread of worms in case of an infection.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n10 / 93\n\n\nPrevention and Protection Against Worms (2/2)\nDisable Unnecessary Services\nTurn off services and ports that are not needed to reduce the attack\nsurface that worms can exploit.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n11 / 93\n\n\nDetection and Prevention Algorithms\nDetection Algorithms\nSignature-Based Detection\nHeuristic-Based Detection\nBehavioral-Based Detection\nAnomaly-Based Detection",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "t]ac[dot]in\nSeptember 5, 2024\n11 / 93\n\n\nDetection and Prevention Algorithms\nDetection Algorithms\nSignature-Based Detection\nHeuristic-Based Detection\nBehavioral-Based Detection\nAnomaly-Based Detection\nSandboxing\nStatic Code Analysis\nPrevention Algorithms\nSignature-Based Prevention\nBehavioral Prevention\nNetwork-Based Prevention\nPatch Management\nAccess Control\nNetwork Segmentation\nLeast Privilege Principle\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n12 / 93\n\n\nSignature-Based Prevention Algorithm\nSignature Database Creation:\nSignature Definition: Each signature represents a specific pattern of malicious activity.\nThese patterns could be sequences of bytes, hashes of files, or known exploit sequences.\nMathematical Representation: Let S = {s1, s2, . . . , sn} be the set of all signatures\nwhere each si is a signature defined in a specific format (e.g., byte sequences).\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n13 / 93\n\n\nSignature-Based Prevention Algorithm\nSignature Database Creation:\nSignature Definition: Each signature represents a specific pattern of malicious activity.\nThese patterns could be sequences of bytes, has",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 7,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "nature-Based Prevention Algorithm\nSignature Database Creation:\nSignature Definition: Each signature represents a specific pattern of malicious activity.\nThese patterns could be sequences of bytes, hashes of files, or known exploit sequences.\nMathematical Representation: Let S = {s1, s2, . . . , sn} be the set of all signatures\nwhere each si is a signature defined in a specific format (e.g., byte sequences).\nData Collection:\nIncoming Data: Let D represent the incoming data stream which needs to be analyzed\nfor threats.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n13 / 93\n\n\nSignature-Based Prevention Algorithm\nSignature Database Creation:\nSignature Definition: Each signature represents a specific pattern of malicious activity.\nThese patterns could be sequences of bytes, hashes of files, or known exploit sequences.\nMathematical Representation: Let S = {s1, s2, . . . , sn} be the set of all signatures\nwhere each si is a signature defined in a specific format (e.g., byte sequences).\nData Collection:\nIncoming Data: Let D represent the incoming data stream which needs to be analyzed\nfor threats.\nPattern Matching:\nMatching Process: For each signature si in",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 8,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "t (e.g., byte sequences).\nData Collection:\nIncoming Data: Let D represent the incoming data stream which needs to be analyzed\nfor threats.\nPattern Matching:\nMatching Process: For each signature si in the signature database S, the algorithm\nchecks if si exists in the incoming data D.\nMathematical Operation: This can be represented as a search operation where the\nalgorithm searches for occurrences of si in D.\nNaive Search: For each si, scan through D to find if si is a substring of D. This is a\nbasic form of pattern matching with a time complexity of O(m · n), where m is the length\nof D and n is the length of si.\nOptimized Search: Using algorithms like Knuth-Morris-Pratt or Boyer-Moore can improve\nsearch efficiency, potentially reducing time complexity to O(m + n) in practice.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n13 / 93\n\n\nSignature-Based Prevention Algorithm\nSignature Database Creation:\nSignature Definition: Each signature represents a specific pattern of malicious activity.\nThese patterns could be sequences of bytes, hashes of files, or known exploit sequences.\nMathematical Representation: Let S = {s1, s2, . . . , sn} be the set of all signa",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 9,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "attern of malicious activity.\nThese patterns could be sequences of bytes, hashes of files, or known exploit sequences.\nMathematical Representation: Let S = {s1, s2, . . . , sn} be the set of all signatures\nwhere each si is a signature defined in a specific format (e.g., byte sequences).\nData Collection:\nIncoming Data: Let D represent the incoming data stream which needs to be analyzed\nfor threats.\nPattern Matching:\nMatching Process: For each signature si in the signature database S, the algorithm\nchecks if si exists in the incoming data D.\nMathematical Operation: This can be represented as a search operation where the\nalgorithm searches for occurrences of si in D.\nNaive Search: For each si, scan through D to find if si is a substring of D. This is a\nbasic form of pattern matching with a time complexity of O(m · n), where m is the length\nof D and n is the length of si.\nOptimized Search: Using algorithms like Knuth-Morris-Pratt or Boyer-Moore can improve\nsearch efficiency, potentially reducing time complexity to O(m + n) in practice.\nDetection and Prevention:\nDetection: If a signature si is found in D, a match is detected.\nPrevention Actions: Based on the detected signatures, predefi",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 10,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ducing time complexity to O(m + n) in practice.\nDetection and Prevention:\nDetection: If a signature si is found in D, a match is detected.\nPrevention Actions: Based on the detected signatures, predefined actions are taken, such\nas blocking the data, alerting the user, or logging the event.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n13 / 93\n\n\nExample: Byte Sequence Matching\nExample Scenario: Let’s consider a simple example where D is a byte stream, and each\nsignature si is a sequence of bytes.\nSignature Database Example:\ns1 = 0x90, 0x90, 0x90 (NOP sled)\ns2 = 0xDE, 0xAD, 0xBE, 0xEF (Example signature)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n14 / 93\n\n\nExample: Byte Sequence Matching\nExample Scenario: Let’s consider a simple example where D is a byte stream, and each\nsignature si is a sequence of bytes.\nSignature Database Example:\ns1 = 0x90, 0x90, 0x90 (NOP sled)\ns2 = 0xDE, 0xAD, 0xBE, 0xEF (Example signature)\nData to Scan:\nD = 0x00, 0x00, 0x90, 0x90, 0x90, 0xAB, 0xCD\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n14 / 93\n\n\nExample: Byte Sequence Matching\nExample Scenario: Let’s cons",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 11,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "Scan:\nD = 0x00, 0x00, 0x90, 0x90, 0x90, 0xAB, 0xCD\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n14 / 93\n\n\nExample: Byte Sequence Matching\nExample Scenario: Let’s consider a simple example where D is a byte stream, and each\nsignature si is a sequence of bytes.\nSignature Database Example:\ns1 = 0x90, 0x90, 0x90 (NOP sled)\ns2 = 0xDE, 0xAD, 0xBE, 0xEF (Example signature)\nData to Scan:\nD = 0x00, 0x00, 0x90, 0x90, 0x90, 0xAB, 0xCD\nMatching Process:\nFor s1: Scan D for the byte sequence 0x90, 0x90, 0x90.\nFor s2: Scan D for the byte sequence 0xDE, 0xAD, 0xBE, 0xEF.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n14 / 93\n\n\nExample: Byte Sequence Matching\nExample Scenario: Let’s consider a simple example where D is a byte stream, and each\nsignature si is a sequence of bytes.\nSignature Database Example:\ns1 = 0x90, 0x90, 0x90 (NOP sled)\ns2 = 0xDE, 0xAD, 0xBE, 0xEF (Example signature)\nData to Scan:\nD = 0x00, 0x00, 0x90, 0x90, 0x90, 0xAB, 0xCD\nMatching Process:\nFor s1: Scan D for the byte sequence 0x90, 0x90, 0x90.\nFor s2: Scan D for the byte sequence 0xDE, 0xAD, 0xBE, 0xEF.\nResult:\ns1 is found at position 2 in D, so a match is detect",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 12,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "0xCD\nMatching Process:\nFor s1: Scan D for the byte sequence 0x90, 0x90, 0x90.\nFor s2: Scan D for the byte sequence 0xDE, 0xAD, 0xBE, 0xEF.\nResult:\ns1 is found at position 2 in D, so a match is detected, and appropriate action is taken.\ns2 is not found in D, so no action is taken for s2.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n14 / 93\n\n\nExample: Byte Sequence Matching\nExample Scenario: Let’s consider a simple example where D is a byte stream, and each\nsignature si is a sequence of bytes.\nSignature Database Example:\ns1 = 0x90, 0x90, 0x90 (NOP sled)\ns2 = 0xDE, 0xAD, 0xBE, 0xEF (Example signature)\nData to Scan:\nD = 0x00, 0x00, 0x90, 0x90, 0x90, 0xAB, 0xCD\nMatching Process:\nFor s1: Scan D for the byte sequence 0x90, 0x90, 0x90.\nFor s2: Scan D for the byte sequence 0xDE, 0xAD, 0xBE, 0xEF.\nResult:\ns1 is found at position 2 in D, so a match is detected, and appropriate action is taken.\ns2 is not found in D, so no action is taken for s2.\nNote: A NOP sled is a sequence of ”No Operation” (NOP) instructions placed in the memory\narea where an attacker intends to execute malicious code. Its purpose is to create a large,\ncontiguous region of memory that does",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 13,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "s a sequence of ”No Operation” (NOP) instructions placed in the memory\narea where an attacker intends to execute malicious code. Its purpose is to create a large,\ncontiguous region of memory that does nothing (i.e., it executes no operations), allowing the\nattacker to direct the execution flow to any part of this region and still eventually reach the\nmalicious payload.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n14 / 93\n\n\nLimitations and Mathematical Extensions\nLimitations\nSignature-Based Detection Limitations\nThis approach only detects known threats. It cannot identify new, unknown\nthreats that do not have corresponding signatures.\nThe efficiency of the matching process can vary based on the size of the\ndatabase and the complexity of the signatures.\nMathematical Extensions\nProbabilistic Models\nSome systems use probabilistic models or machine learning to improve detection\naccuracy and reduce false positives.\nHash-Based Matching\nUsing hash functions to represent signatures and hashes of data can speed up the\nmatching process.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n15 / 93\n\n\nBehavioral Prevention Algorithm\nBehav",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 14,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "represent signatures and hashes of data can speed up the\nmatching process.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n15 / 93\n\n\nBehavioral Prevention Algorithm\nBehavioral Prevention in cybersecurity is a technique used to detect and\nprevent threats based on the behavior of programs or processes, rather\nthan relying on known signatures. This approach aims to identify and\nblock malicious activities by analyzing deviations from normal behavior\npatterns.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n16 / 93\n\n\nBehavioral Prevention Algorithm (Step 1):Data Collection and\nProfiling\nNormal Behavior Profiling:\nDefinition: Establish a profile of normal behavior for programs or\nprocesses. This profile includes typical resource usage patterns,\nsystem calls, file operations, network activity, etc.\nMathematical Representation: Let B represent the normal\nbehavior profile. This profile can be defined as a set of parameters or\nstatistical distributions for various metrics.\nFor example, if analyzing CPU usage, BCPU might be modeled as a\nnormal distribution N(µCPU, σCPU) where µCPU is the mean CPU\nusage and σCPU is the standard deviat",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 15,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "al distributions for various metrics.\nFor example, if analyzing CPU usage, BCPU might be modeled as a\nnormal distribution N(µCPU, σCPU) where µCPU is the mean CPU\nusage and σCPU is the standard deviation.\nData Collection:\nCollect data from the system or application to build the normal\nbehavior profile. This data can be represented as a vector of features\nX = [x1, x2, . . . , xn] where each xi represents a specific behavior\nmetric.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n17 / 93\n\n\nBehavioral Prevention Algorithm (Step 2):Behavior Analysis\nFeature Extraction:\nExtract features from ongoing system activities or program executions. Let\nXt = [x1,t, x2,t, . . . , xn,t] denote the feature vector at time t.\nBehavioral Modeling:\nStatistical Analysis: Use statistical models to represent the normal behavior. For\nexample, a multivariate normal distribution can be used to model normal behavior across\nmultiple features.\nMean Vector (µ): Average of observed features.\nCovariance Matrix (Σ): Measures the variance and correlation between features.\nThe normal behavior B can be represented as N(µ, Σ).\nAnomaly Detection:\nMahalanobis Distance: Measure the distance of",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 16,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "es.\nCovariance Matrix (Σ): Measures the variance and correlation between features.\nThe normal behavior B can be represented as N(µ, Σ).\nAnomaly Detection:\nMahalanobis Distance: Measure the distance of the current behavior Xt from the normal\nbehavior profile using the Mahalanobis distance.\nDM(Xt) =\nq\n(Xt −µ)T Σ−1(Xt −µ)\nwhere DM(Xt) is the Mahalanobis distance, µ is the mean vector of normal behavior, and\nΣ−1 is the inverse of the covariance matrix.\nThresholding: Compare the Mahalanobis distance with a predefined threshold θ. If\nDM(Xt) > θ, the behavior is considered anomalous.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n18 / 93\n\n\nBehavioral Prevention Algorithm (Step 3):Response\nMechanism\nAlert Generation:\nIf the behavior is detected as anomalous, generate an alert or log the\nevent.\nPreventive Actions:\nBased on the severity of the detected anomaly, take preventive\nactions such as blocking the process, isolating the system, or\nterminating the suspicious activity.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n19 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 17,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "activity.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n19 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting vulnerabilities in systems.\nTo prevent the spread of worms, it is crucial to detect and contain\nthem early.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n20 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting vulnerabilities in systems.\nTo prevent the spread of worms, it is crucial to detect and contain\nthem early.\nWe use a Susceptible-Infected-Recovered (SIR) model to\nmathematically represent the propagation dynamics.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n20 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting vulnerabilities in systems.\nTo prevent the spread of worms, it is crucial to detect and contain\nthem early.\nWe use a Susceptible-Infected-Recovered (SIR) model to\nmathematically represent the propagation dynamics.\nThe susceptible-infected-Recovered (SIR) model can be applied to\nnetwork worm preventi",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 18,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "early.\nWe use a Susceptible-Infected-Recovered (SIR) model to\nmathematically represent the propagation dynamics.\nThe susceptible-infected-Recovered (SIR) model can be applied to\nnetwork worm prevention by treating the network as a population and\nthe worm as an infectious disease.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n20 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting vulnerabilities in systems.\nTo prevent the spread of worms, it is crucial to detect and contain\nthem early.\nWe use a Susceptible-Infected-Recovered (SIR) model to\nmathematically represent the propagation dynamics.\nThe susceptible-infected-Recovered (SIR) model can be applied to\nnetwork worm prevention by treating the network as a population and\nthe worm as an infectious disease.\nThe SIR model is a mathematical model used to describe the spread\nof infectious diseases.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n20 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting vulnerabilities in systems.\nTo prevent the spread of worms, it is cr",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 19,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "in\nSeptember 5, 2024\n20 / 93\n\n\nNetwork-Based Prevention\nWorms are malicious programs that propagate through a network by\nexploiting vulnerabilities in systems.\nTo prevent the spread of worms, it is crucial to detect and contain\nthem early.\nWe use a Susceptible-Infected-Recovered (SIR) model to\nmathematically represent the propagation dynamics.\nThe susceptible-infected-Recovered (SIR) model can be applied to\nnetwork worm prevention by treating the network as a population and\nthe worm as an infectious disease.\nThe SIR model is a mathematical model used to describe the spread\nof infectious diseases.\nIt divides the population into three compartments: Susceptible (S),\nInfected (I), and Recovered (R).\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n20 / 93\n\n\nMathematical Modeling of Network Traffic\nLet:\nN: Total number of nodes (hosts) in the network.\nt: Time variable (continuous time).\nS(t): Number of susceptible nodes at time t.\nI(t): Number of infected nodes at time t.\nR(t): Number of removed (recovered) nodes at time t.\nλ: Infection rate (worm spread rate from infected to susceptible nodes).\nδ: Recovery rate (rate at which infected nodes are removed).\nAd",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 20,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "at time t.\nR(t): Number of removed (recovered) nodes at time t.\nλ: Infection rate (worm spread rate from infected to susceptible nodes).\nδ: Recovery rate (rate at which infected nodes are removed).\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n21 / 93\n\n\nDifferential Equations for Worm Propagation\nSIR Model Equations\ndS(t)\ndt\n= −λS(t)I(t)\n(1)\ndI(t)\ndt\n= λS(t)I(t) −δI(t)\n(2)\ndR(t)\ndt\n= δI(t)\n(3)\nThese equations model the rate of change in susceptible, infected,\nand recovered nodes.\nThe goal is to minimize I(t), the number of infected nodes, over time.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n22 / 93\n\n\nPrevention Strategy\nMonitor network traffic for abnormal patterns indicating worm\npropagation.\nUse early warning systems to detect rapid increases in I(t).\nIsolate infected nodes to prevent further spread:\nIsolate Node\nif\nI(t) > Threshold\n(4)\nApply patches to susceptible nodes to reduce λ.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n23 / 93\n\n\nNumerical Example - Initial Conditions\nConsider a network of 1000 computers.\nInitial conditions:\nS(0) = 990 (Susceptible computers)\nI(0) = 10 (In",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 21,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n23 / 93\n\n\nNumerical Example - Initial Conditions\nConsider a network of 1000 computers.\nInitial conditions:\nS(0) = 990 (Susceptible computers)\nI(0) = 10 (Infected computers)\nR(0) = 0 (Recovered/Patched computers)\nParameters:\nInfection rate β = 0.3\nRecovery rate γ = 0.1\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n24 / 93\n\n\nMathematical Equations\nChange in Susceptible (S):\ndS\ndt = −β · S · I\nN\nChange in Infected (I):\ndI\ndt = β · S · I\nN −γ · I\nChange in Recovered (R):\ndR\ndt = γ · I\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n25 / 93\n\n\nTime Step 0 (t = 0)\nInitial conditions:\nS(0) = 990\nI(0) = 10\nR(0) = 0\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n26 / 93\n\n\nTime Step 1 (t = 1)\nChange in Susceptible (S):\n∆S = −β · S(0) · I(0)\nN\n∆S = −0.3 · 990 ·\n10\n1000 = −2.97 ≈−3\nChange in Infected (I):\n∆I = β · S(0) · I(0)\nN\n−γ · I(0)\n∆I = 2.97 −1 = 1.97 ≈2\nChange in Recovered (R):\n∆R = γ · I(0)\n∆R = 0.1 · 10 = 1\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n27 / 93\n\n\nUpdated Values at Time Step 1\nS(1) = S(0) + ∆S = 990 −3 =",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 22,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ange in Recovered (R):\n∆R = γ · I(0)\n∆R = 0.1 · 10 = 1\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n27 / 93\n\n\nUpdated Values at Time Step 1\nS(1) = S(0) + ∆S = 990 −3 = 987\nI(1) = I(0) + ∆I = 10 + 2 = 12\nR(1) = R(0) + ∆R = 0 + 1 = 1\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n28 / 93\n\n\nTime Step 2 (t = 2)\nChange in Susceptible (S):\n∆S = −0.3 · 987 ·\n12\n1000 = −3.56 ≈−4\nChange in Infected (I):\n∆I = 0.3 · 987 ·\n12\n1000 −0.1 · 12 = 2.36 ≈2\nChange in Recovered (R):\n∆R = 0.1 · 12 = 1.2 ≈1\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n29 / 93\n\n\nUpdated Values at Time Step 2\nS(2) = S(1) + ∆S = 987 −4 = 983\nI(2) = I(1) + ∆I = 12 + 2 = 14\nR(2) = R(1) + ∆R = 1 + 1 = 2\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n30 / 93\n\n\nReal-Time SIR Model Extension\nReal-Time Data Integration:\nContinuously collecting data from network monitoring systems.\nMonitoring the number of susceptible, infected, and recovered\ncomputers in real-time.\nDynamic Parameter Adjustment:\nAdjusting parameters like the infection rate (β) and recovery rate (γ)\nbased on real-time observations.\nAdaptin",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 23,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "sceptible, infected, and recovered\ncomputers in real-time.\nDynamic Parameter Adjustment:\nAdjusting parameters like the infection rate (β) and recovery rate (γ)\nbased on real-time observations.\nAdapting to changing network conditions and worm behavior.\nFeedback Mechanisms:\nImplementing feedback loops for immediate action based on model\npredictions.\nActions include isolating infected computers or updating security\npolicies.\nPrediction and Control:\nUsing the model to predict future worm propagation trends.\nControlling the spread by applying appropriate security measures.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n31 / 93\n\n\nExample 2: Initial Setup\nNetwork Size: 1000 computers\nInitial Conditions: S(0) = 980, I(0) = 20, R(0) = 0\nInfection Rate: β = 0.3\nRecovery Rate: γ = 0.1\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n32 / 93\n\n\nDynamic Update at t = 1 Minute\nObservations indicate increased infection rate.\nUpdated Infection Rate: β = 0.35\nUpdated Recovery Rate: γ = 0.1\nCalculations:\n∆S = −7,\n∆I = 5,\n∆R = 2\nUpdated Values: S(1) = 973, I(1) = 25, R(1) = 2\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptemb",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 24,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "Rate: β = 0.35\nUpdated Recovery Rate: γ = 0.1\nCalculations:\n∆S = −7,\n∆I = 5,\n∆R = 2\nUpdated Values: S(1) = 973, I(1) = 25, R(1) = 2\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n33 / 93\n\n\nDynamic Update at t = 2 Minutes\nRecovery efforts improve, reducing infection rate.\nUpdated Infection Rate: β = 0.3\nUpdated Recovery Rate: γ = 0.2\nCalculations:\n∆S = −7,\n∆I = 2,\n∆R = 5\nUpdated Values: S(2) = 966, I(2) = 27, R(2) = 7\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n34 / 93\n\n\nSIR Model Results\nDay (t)\nS(t)\nI(t)\nR(t)\n0\n980.00\n20.00\n0.00\n1\n974.12\n24.44\n1.44\n2\n966.99\n29.75\n3.26\n3\n958.17\n35.88\n5.95\n4\n947.94\n42.80\n9.26\n5\n936.56\n50.41\n13.03\n6\n924.16\n58.63\n17.21\n7\n910.86\n67.27\n21.87\n8\n896.70\n76.12\n27.17\n9\n881.67\n84.92\n33.41\n10\n865.75\n93.35\n40.90\n11\n848.88\n101.06\n49.26\n12\n830.95\n107.64\n58.41\nTable: SIR model simulation results until S(t) approaches zero\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n35 / 93\n\n\nPatch Management\nPatch Management Process\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n36 / 93\n\n\nIntroduction to Patch Management\nPatch management is the process",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 25,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "93\n\n\nPatch Management\nPatch Management Process\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n36 / 93\n\n\nIntroduction to Patch Management\nPatch management is the process of applying updates to software,\ndrivers, and firmware to protect against vulnerabilities. Effective patch\nmanagement also helps ensure the best operating performance of sys-\ntems, boosting productivity.\nPatch management involves the process of distributing and applying\nupdates to software to correct vulnerabilities.\nPatches are crucial in preventing worms and other malware from ex-\nploiting known security flaws.\nRegular patching helps maintain the integrity, confidentiality, and avail-\nability of systems.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n37 / 93\n\n\nImportance of Patch Management\nVulnerability Fixes: Patches close security gaps that worms and\nmalware exploit.\nCompliance: Helps organizations meet regulatory requirements (e.g.,\nGDPR, HIPAA).\nPerformance Improvements: Patches can also improve software\nstability and performance.\nMinimized Downtime: Regular patching can prevent major system\noutages due to exploits.\nAdarsh Kumar\nAdarsh[dot]Kumar[a",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 26,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "rmance Improvements: Patches can also improve software\nstability and performance.\nMinimized Downtime: Regular patching can prevent major system\noutages due to exploits.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n38 / 93\n\n\nComparison of Patch Management Methods for Worm Prevention\nPatch\nManagement\nMethod\nPerformance\nAdvantages\nDisadvantages\nUse Case\nAutomated Patch Manage-\nment Tools\nHigh\nReduces manual effort, ensures\nconsistency, fast deployment\nRequires\nsetup\nand\nmainte-\nnance; potential deployment of\nfaulty patches\nLarge\norganizations\nneeding\nconsistent\npatch deployment\nCentralized Patch Manage-\nment\nHigh\nBetter control, reduced band-\nwidth usage, efficient manage-\nment\nPotential single point of failure,\ncomplex setup\nOrganizations\nwith\nmany devices in multi-\nple locations\nRegular Patch Testing and\nValidation\nMedium\nReduces\npatch-related\nissues,\nensures compatibility and stabil-\nity\nSlower deployment, requires ad-\nditional resources\nEnvironments where up-\ntime and stability are\ncritical\nPatch\nPrioritization\nand\nRisk Assessment\nVariable\nFocuses on critical vulnerabili-\nties, optimized resource use\nLess critical patches might be\ndelayed, potentia",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 27,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ere up-\ntime and stability are\ncritical\nPatch\nPrioritization\nand\nRisk Assessment\nVariable\nFocuses on critical vulnerabili-\nties, optimized resource use\nLess critical patches might be\ndelayed, potential exposure\nSecurity-sensitive\nenvi-\nronments\nPatch Management Policy\nand Compliance\nMedium\nEstablishes clear procedures, en-\nhances\naccountability,\nensures\nregular updates\nRequires audits and adherence,\nchallenging to enforce\nAll organizations, partic-\nularly regulated indus-\ntries\nVulnerability Scanning and\nPatch Monitoring\nHigh\nEarly detection of vulnerabilities,\nensures patch compliance\nFalse\npositives/negatives,\nun-\nnecessary work or missed threats\nDynamic\nand\nevolving\nIT environments\nThird-Party Patch Manage-\nment\nHigh\nComprehensive security cover-\nage, reduces attack surface\nComplexity in managing patches\nfor various software vendors\nOrganizations\nusing\na\nwide\nrange\nof\nthird-\nparty software\nEmergency\nPatch\nDeploy-\nment Protocol\nHigh (criti-\ncal)\nQuick response to critical vulner-\nabilities, reduces exposure win-\ndow\nPotential disruption,\nhigh ur-\ngency requires readiness\nHigh exposure to zero-\nday vulnerabilities\nCloud-Based\nPatch\nMan-\nagement Solutions\nHigh\nScalability, remote m",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 28,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "lities, reduces exposure win-\ndow\nPotential disruption,\nhigh ur-\ngency requires readiness\nHigh exposure to zero-\nday vulnerabilities\nCloud-Based\nPatch\nMan-\nagement Solutions\nHigh\nScalability, remote management,\nreduced on-prem infrastructure\nDependence on internet connec-\ntivity, potential latency issues\nRemote\nor\ngeographi-\ncally\ndispersed\ninfras-\ntructure\nEnd-User\nAwareness\nand\nTraining\nLow\n(di-\nrectly)\nEnhances security culture, re-\nduces risk of delayed updates\nRelies on user participation, in-\ndirect impact on patch perfor-\nmance\nAny organization aiming\nfor holistic security\nTable: Comparison of Patch Management Methods for Worm Prevention\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n39 / 93\n\n\nPatch Management Methods and Example Tools\nPatch Management Method\nExample Tools\nAutomated Patch Management Tools\nMicrosoft SCCM, SolarWinds Patch Manager,\nIvanti Patch Management\nCentralized Patch Management\nIBM\nBigFix,\nManageEngine\nPatch\nManager\nPlus, Windows Server Update Services (WSUS)\nRegular Patch Testing and Validation\nQualys\nPatch\nManagement,\nGFI\nLanGuard,\nIvanti Security Controls\nPatch Prioritization and Risk Assessment\nRapid7 InsightVM, Nessus,",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 29,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ws Server Update Services (WSUS)\nRegular Patch Testing and Validation\nQualys\nPatch\nManagement,\nGFI\nLanGuard,\nIvanti Security Controls\nPatch Prioritization and Risk Assessment\nRapid7 InsightVM, Nessus, Tenable.sc\nPatch Management Policy and Compli-\nance\nMicrosoft SCCM, Symantec Endpoint Manage-\nment, Qualys Patch Management\nVulnerability Scanning and Patch Moni-\ntoring\nQualys\nVulnerability\nManagement,\nNessus,\nOpenVAS\nThird-Party Patch Management\nSolarWinds\nPatch\nManager,\nGFI\nLanGuard,\nManageEngine Patch Manager Plus\nEmergency Patch Deployment Protocol\nIBM BigFix, Automox, Symantec Endpoint Man-\nagement\nCloud-Based Patch Management Solu-\ntions\nAutomox, Qualys Cloud Platform, Microsoft In-\ntune\nEnd-User Awareness and Training\nKnowBe4, Infosec IQ, SANS Security Awareness\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n40 / 93\n\n\nScenario Setup\nNetwork Size: 1000 computers\nInitial Worm Infection: 10 computers\nPatch Availability: A patch is available to fix the vulnerability\nPatch Deployment Rate: 50 computers per day from susceptible\ncomputers category\nInfection Rate: Each infected computer can infect 2 new computers\nper day\nTimeframe: Analysis over 10 days",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 30,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ulnerability\nPatch Deployment Rate: 50 computers per day from susceptible\ncomputers category\nInfection Rate: Each infected computer can infect 2 new computers\nper day\nTimeframe: Analysis over 10 days\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n41 / 93\n\n\nInitial Conditions\nSusceptible Computers (S): 990\nInfected Computers (I): 10\nRecovered/Patched Computers (R): 0\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n42 / 93\n\n\nDay 1: Patch Management and Infection Spread\nInfection Spread: I=10 infected computers infect 10x2= 20 new\ncomputers\nS = 990 −20 = 970,\nI = 10 + 20 = 30\nPatch Deployment: 50 computers patched\nS = 970 −50 = 920,\nR = 0 + 50 = 50\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n43 / 93\n\n\nDay 2: Patch Management and Infection Spread\nInfection Spread: I=30 infected computers infect 30x2= 60 new\ncomputers\nS = 920 −60 = 860,\nI = 30 + 60 = 90\nPatch Deployment: 50 more computers patched\nS = 860 −50 = 810,\nR = 50 + 50 = 100\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n44 / 93\n\n\nDay 3: Patch Management and Infection Spread\nInfection Spread: I=90 infecte",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 31,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "S = 860 −50 = 810,\nR = 50 + 50 = 100\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n44 / 93\n\n\nDay 3: Patch Management and Infection Spread\nInfection Spread: I=90 infected computers infect 180 new\ncomputers\nS = 810 −180 = 630,\nI = 90 + 180 = 270\nPatch Deployment: 50 more computers patched\nS = 630 −50 = 580,\nR = 100 + 50 = 150\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n45 / 93\n\n\nDay 4: Patch Management and Infection Spread\nInfection Spread: 270 infected computers infect 540 new computers\nS = 580 −540 = 40,\nI = 270 + 540 = 810\nPatch Deployment: 50 more computers patched\nS = 40−50 = −10 (No more susceptible left),\nR = 150+50 = 200\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n46 / 93\n\n\nDay 5: Patch Management and Infection Spread\nInfection Spread: All remaining 40 computers get infected\nS = 0,\nI = 810 + 40 = 850\nPatch Deployment: No more susceptible computers left to patch\nS = 0,\nR = 200\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n47 / 93\n\n\nAnalysis of Results\nBy Day 5, all susceptible computers are either infected or patched.\nTotal infected computers: 850",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 32,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "h Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n47 / 93\n\n\nAnalysis of Results\nBy Day 5, all susceptible computers are either infected or patched.\nTotal infected computers: 850\nTotal patched computers: 200\nPatch management initially slowed the spread of the worm but was\nnot enough to prevent widespread infection due to the high infection\nrate.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n48 / 93\n\n\nExample 1: Automated Patch Management Tools\nScenario\nAn organization with 1,000 computers is at risk of infection from a newly\ndiscovered worm exploiting a zero-day vulnerability in a commonly used\nsoftware application.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n49 / 93\n\n\nExample 1: Automated Patch Management Tools\nScenario\nAn organization with 1,000 computers is at risk of infection from a newly\ndiscovered worm exploiting a zero-day vulnerability in a commonly used\nsoftware application.\nInitial Vulnerability: All 1,000 computers are initially vulnerable.\nPatch Availability: A patch is released by the software vendor.\nAutomated Patch Deployment Rate: Using automated tools like\nMicrosoft SCCM, patch",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 33,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ability: All 1,000 computers are initially vulnerable.\nPatch Availability: A patch is released by the software vendor.\nAutomated Patch Deployment Rate: Using automated tools like\nMicrosoft SCCM, patches are deployed to 200 computers per hour.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n49 / 93\n\n\nExample 1: Automated Patch Management Tools\nScenario\nAn organization with 1,000 computers is at risk of infection from a newly\ndiscovered worm exploiting a zero-day vulnerability in a commonly used\nsoftware application.\nInitial Vulnerability: All 1,000 computers are initially vulnerable.\nPatch Availability: A patch is released by the software vendor.\nAutomated Patch Deployment Rate: Using automated tools like\nMicrosoft SCCM, patches are deployed to 200 computers per hour.\nImpact\nAfter 1 hour: 200 computers patched, 800 computers still vulnerable.\nAfter 2 hours: 400 computers patched, 600 computers still vulnerable.\nAfter 3 hours: 600 computers patched, 400 computers still vulnerable.\nAfter 5 hours: All 1,000 computers patched, no computers vulnerable.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n49 / 93\n\n\nExample 2: Centrali",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 34,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "uters still vulnerable.\nAfter 5 hours: All 1,000 computers patched, no computers vulnerable.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n49 / 93\n\n\nExample 2: Centralized Patch Management\nScenario\nA multinational organization with 5,000 devices distributed across five locations worldwide faces\na threat from a worm exploiting a known vulnerability in its email client.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n50 / 93\n\n\nExample 2: Centralized Patch Management\nScenario\nA multinational organization with 5,000 devices distributed across five locations worldwide faces\na threat from a worm exploiting a known vulnerability in its email client.\nInitial Vulnerability: All 5,000 devices are vulnerable.\nPatch Availability: A patch is available and needs to be deployed.\nCentralized Patch Deployment Rate: Using tools like IBM BigFix, patches are deployed\nto 500 devices per location per hour.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n50 / 93\n\n\nExample 2: Centralized Patch Management\nScenario\nA multinational organization with 5,000 devices distributed across five locations worldwide faces\na thr",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 35,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "]upes[dot]ac[dot]in\nSeptember 5, 2024\n50 / 93\n\n\nExample 2: Centralized Patch Management\nScenario\nA multinational organization with 5,000 devices distributed across five locations worldwide faces\na threat from a worm exploiting a known vulnerability in its email client.\nInitial Vulnerability: All 5,000 devices are vulnerable.\nPatch Availability: A patch is available and needs to be deployed.\nCentralized Patch Deployment Rate: Using tools like IBM BigFix, patches are deployed\nto 500 devices per location per hour.\nCalculation\nTotal Devices Patched per Hour:\n500 devices/location × 5 locations = 2, 500 devices/hour\nAfter 1 hour: 2,500 devices patched, 2,500 vulnerable.\nAfter 2 hours: 5,000 devices patched, 0 vulnerable.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n50 / 93\n\n\nExample 2: Centralized Patch Management\nScenario\nA multinational organization with 5,000 devices distributed across five locations worldwide faces\na threat from a worm exploiting a known vulnerability in its email client.\nInitial Vulnerability: All 5,000 devices are vulnerable.\nPatch Availability: A patch is available and needs to be deployed.\nCentralized Patch Deployment Rate: Using",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 36,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "vulnerability in its email client.\nInitial Vulnerability: All 5,000 devices are vulnerable.\nPatch Availability: A patch is available and needs to be deployed.\nCentralized Patch Deployment Rate: Using tools like IBM BigFix, patches are deployed\nto 500 devices per location per hour.\nCalculation\nTotal Devices Patched per Hour:\n500 devices/location × 5 locations = 2, 500 devices/hour\nAfter 1 hour: 2,500 devices patched, 2,500 vulnerable.\nAfter 2 hours: 5,000 devices patched, 0 vulnerable.\nOutcome\nUsing centralized patch management, all devices across the organization are patched within 2\nhours, minimizing the risk of a worm infection.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n50 / 93\n\n\nExample 3: Patch Prioritization and Risk Assessment\nScenario\nA healthcare organization with 2,000 devices has a critical vulnerability affecting its patient\nmanagement software. The organization decides to prioritize patching high-risk devices first.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n51 / 93\n\n\nExample 3: Patch Prioritization and Risk Assessment\nScenario\nA healthcare organization with 2,000 devices has a critical vulnerability",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 37,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "t]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n51 / 93\n\n\nExample 3: Patch Prioritization and Risk Assessment\nScenario\nA healthcare organization with 2,000 devices has a critical vulnerability affecting its patient\nmanagement software. The organization decides to prioritize patching high-risk devices first.\nInitial Vulnerability: 2,000 devices are vulnerable.\nPatch Deployment Plan:\nHigh-risk devices (e.g., those connected to critical patient systems):\n800 devices, patched within 1 day.\nMedium-risk devices: 700 devices, patched within 2 days.\nLow-risk devices: 500 devices, patched within 3 days.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n51 / 93\n\n\nExample 3: Patch Prioritization and Risk Assessment\nScenario\nA healthcare organization with 2,000 devices has a critical vulnerability affecting its patient\nmanagement software. The organization decides to prioritize patching high-risk devices first.\nInitial Vulnerability: 2,000 devices are vulnerable.\nPatch Deployment Plan:\nHigh-risk devices (e.g., those connected to critical patient systems):\n800 devices, patched within 1 day.\nMedium-risk devices: 700 devices, patched within 2 days.\nLow-risk dev",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 38,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": ".\nPatch Deployment Plan:\nHigh-risk devices (e.g., those connected to critical patient systems):\n800 devices, patched within 1 day.\nMedium-risk devices: 700 devices, patched within 2 days.\nLow-risk devices: 500 devices, patched within 3 days.\nCalculation\nDay 1: 800 high-risk devices patched, 1,200 devices remain vulnerable.\nDay 2: Additional 700 medium-risk devices patched, 500 devices remain vulnerable.\nDay 3: All 500 low-risk devices patched, 0 devices remain vulnerable.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n51 / 93\n\n\nExample 3: Patch Prioritization and Risk Assessment\nScenario\nA healthcare organization with 2,000 devices has a critical vulnerability affecting its patient\nmanagement software. The organization decides to prioritize patching high-risk devices first.\nInitial Vulnerability: 2,000 devices are vulnerable.\nPatch Deployment Plan:\nHigh-risk devices (e.g., those connected to critical patient systems):\n800 devices, patched within 1 day.\nMedium-risk devices: 700 devices, patched within 2 days.\nLow-risk devices: 500 devices, patched within 3 days.\nCalculation\nDay 1: 800 high-risk devices patched, 1,200 devices remain vulnerable.\nDay 2: A",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 39,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "dium-risk devices: 700 devices, patched within 2 days.\nLow-risk devices: 500 devices, patched within 3 days.\nCalculation\nDay 1: 800 high-risk devices patched, 1,200 devices remain vulnerable.\nDay 2: Additional 700 medium-risk devices patched, 500 devices remain vulnerable.\nDay 3: All 500 low-risk devices patched, 0 devices remain vulnerable.\nOutcome\nBy prioritizing patch deployment based on risk, the healthcare organization reduces the risk of a\nworm infection impacting critical systems within 24 hours while fully securing all devices within\n3 days.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n51 / 93\n\n\nExample 4: Emergency Patch Deployment Protocol\nScenario\nA financial institution with 10,000 endpoints detects a worm exploiting a\nzero-day vulnerability. An emergency patch deployment is initiated.\nInitial Vulnerability: All 10,000 endpoints are vulnerable.\nEmergency Deployment Rate: Using emergency protocols and\ntools like Automox, patches are deployed to 1,000 endpoints per hour.\nCalculation\nAfter 1 hour: 1,000 endpoints patched, 9,000 vulnerable.\nAfter 5 hours: 5,000 endpoints patched, 5,000 vulnerable.\nAfter 10 hours: 10,000 endpoints patched, 0",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 40,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "to 1,000 endpoints per hour.\nCalculation\nAfter 1 hour: 1,000 endpoints patched, 9,000 vulnerable.\nAfter 5 hours: 5,000 endpoints patched, 5,000 vulnerable.\nAfter 10 hours: 10,000 endpoints patched, 0 vulnerable.\nOutcome\nThe emergency patch deployment protocol patches all endpoints within 10\nhours, drastically reducing the potential impact of the worm.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n52 / 93\n\n\nExample 5: Cloud-Based Patch Management Solutions\nScenario\nA tech company with a distributed workforce (remote) has 3,000 devices connected via the\ncloud. A critical security patch is required for a newly identified worm threat.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n53 / 93\n\n\nExample 5: Cloud-Based Patch Management Solutions\nScenario\nA tech company with a distributed workforce (remote) has 3,000 devices connected via the\ncloud. A critical security patch is required for a newly identified worm threat.\nInitial Vulnerability: All 3,000 devices are vulnerable.\nPatch Deployment via Cloud Management: Using a cloud-based solution like Microsoft\nIntune, patches are pushed remotely.\nDeployment Rate: 500 devices per ho",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 41,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "erability: All 3,000 devices are vulnerable.\nPatch Deployment via Cloud Management: Using a cloud-based solution like Microsoft\nIntune, patches are pushed remotely.\nDeployment Rate: 500 devices per hour.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n53 / 93\n\n\nExample 5: Cloud-Based Patch Management Solutions\nScenario\nA tech company with a distributed workforce (remote) has 3,000 devices connected via the\ncloud. A critical security patch is required for a newly identified worm threat.\nInitial Vulnerability: All 3,000 devices are vulnerable.\nPatch Deployment via Cloud Management: Using a cloud-based solution like Microsoft\nIntune, patches are pushed remotely.\nDeployment Rate: 500 devices per hour.\nCalculation\nAfter 1 hour: 500 devices patched, 2,500 vulnerable.\nAfter 3 hours: 1,500 devices patched, 1,500 vulnerable.\nAfter 6 hours: 3,000 devices patched, 0 vulnerable.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n53 / 93\n\n\nExample 5: Cloud-Based Patch Management Solutions\nScenario\nA tech company with a distributed workforce (remote) has 3,000 devices connected via the\ncloud. A critical security patch is required for a new",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 42,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ample 5: Cloud-Based Patch Management Solutions\nScenario\nA tech company with a distributed workforce (remote) has 3,000 devices connected via the\ncloud. A critical security patch is required for a newly identified worm threat.\nInitial Vulnerability: All 3,000 devices are vulnerable.\nPatch Deployment via Cloud Management: Using a cloud-based solution like Microsoft\nIntune, patches are pushed remotely.\nDeployment Rate: 500 devices per hour.\nCalculation\nAfter 1 hour: 500 devices patched, 2,500 vulnerable.\nAfter 3 hours: 1,500 devices patched, 1,500 vulnerable.\nAfter 6 hours: 3,000 devices patched, 0 vulnerable.\nOutcome\nThe cloud-based patch management system ensures that all remote devices are patched within 6\nhours, providing effective and quick mitigation against the worm threat.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n53 / 93\n\n\nExample 6: Third-Party Patch Management\nScenario\nInitial Vulnerability: 2,000 workstations are potentially vulnerable to worm infections due to\noutdated third-party applications. Patch Deployment Rate: ManageEngine Patch Manager\nPlus can patch 200 workstations per hour. Patching Schedule: Patches are applied overnight to",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 43,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "orm infections due to\noutdated third-party applications. Patch Deployment Rate: ManageEngine Patch Manager\nPlus can patch 200 workstations per hour. Patching Schedule: Patches are applied overnight to\nminimize disruption.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n54 / 93\n\n\nExample 6: Third-Party Patch Management\nScenario\nInitial Vulnerability: 2,000 workstations are potentially vulnerable to worm infections due to\noutdated third-party applications. Patch Deployment Rate: ManageEngine Patch Manager\nPlus can patch 200 workstations per hour. Patching Schedule: Patches are applied overnight to\nminimize disruption.\nCalculation\nAfter 1 hour: 200 workstations patched, 1,800 vulnerable.\nAfter 5 hours: 1,000 workstations patched, 1,000 vulnerable.\nAfter 10 hours: 2,000 workstations patched, 0 vulnerable.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n54 / 93\n\n\nExample 6: Third-Party Patch Management\nScenario\nInitial Vulnerability: 2,000 workstations are potentially vulnerable to worm infections due to\noutdated third-party applications. Patch Deployment Rate: ManageEngine Patch Manager\nPlus can patch 200 workstations per hour",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 44,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "y: 2,000 workstations are potentially vulnerable to worm infections due to\noutdated third-party applications. Patch Deployment Rate: ManageEngine Patch Manager\nPlus can patch 200 workstations per hour. Patching Schedule: Patches are applied overnight to\nminimize disruption.\nCalculation\nAfter 1 hour: 200 workstations patched, 1,800 vulnerable.\nAfter 5 hours: 1,000 workstations patched, 1,000 vulnerable.\nAfter 10 hours: 2,000 workstations patched, 0 vulnerable.\nOutcome\nBy using ManageEngine Patch Manager Plus, the company can ensure that all third-party\napplications across its 2,000 workstations are patched within 10 hours, reducing the risk of worm\ninfections exploiting known vulnerabilities.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n54 / 93\n\n\nKey Insights\nPatch Deployment Rate: Must match or exceed infection rate to\ncontrol worm spread.\nInfection Rate: High infection rates lead to exponential growth;\nquick response is critical.\nEarly Patch Deployment: Patching early can significantly reduce\ninfection spread.\nDynamic Response: Real-time monitoring and adaptive patching\nstrategies can improve worm prevention.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[do",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 45,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": ": Patching early can significantly reduce\ninfection spread.\nDynamic Response: Real-time monitoring and adaptive patching\nstrategies can improve worm prevention.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n55 / 93\n\n\nPatch Management Lifecycle\n1 Detection: Identify vulnerabilities and available patches.\n2 Assessment: Evaluate the relevance and impact of patches.\n3 Prioritization: Prioritize patches based on severity and potential risk.\n4 Deployment: Apply patches to systems in a controlled manner.\n5 Verification: Ensure patches are applied correctly and monitor for\nissues.\n6 Documentation: Record patching activities for future reference and\ncompliance.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n56 / 93\n\n\nPatch Management Algorithm\nAlgorithm Steps\nInput: List of vulnerabilities V = {v1, v2, . . . , vn}, Patch database\nP = {p1, p2, . . . , pm}.\nOutput: Successfully patched systems.\n1 Initialization: Set S = ∅, where S is the set of patched systems.\n2 For each vulnerability vi in V :\nFind corresponding patch pj in P such that pj addresses vi.\nIf pj is not already applied:\nApply pj to affected systems.\nAdd affected syst",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 46,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "the set of patched systems.\n2 For each vulnerability vi in V :\nFind corresponding patch pj in P such that pj addresses vi.\nIf pj is not already applied:\nApply pj to affected systems.\nAdd affected systems to S.\n3 End For\n4 Verification: Check that all systems in S have been patched\ncorrectly.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n57 / 93\n\n\nExamples of Patches for Worm Prevention\nMS17-010 (EternalBlue):\nReleased by Microsoft in March 2017.\nAddressed vulnerabilities in the SMBv1 protocol exploited by the WannaCry ransomware worm.\nImportance: Prevented the spread of WannaCry, which affected over 200,000 computers worldwide, by patching\nthe exploit.\nMS08-067 (Conficker Worm):\nReleased by Microsoft in October 2008.\nFixed a vulnerability in the Windows Server service used by the Conficker worm to spread.\nImportance: Essential in mitigating the spread of Conficker, one of the most widespread network worms,\naffecting millions of systems globally.\nMS04-011 (Sasser Worm):\nReleased by Microsoft in April 2004.\nAddressed a vulnerability in the Local Security Authority Subsystem Service (LSASS) exploited by the Sasser\nworm.\nImportance: Helped prevent the Sa",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 47,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "(Sasser Worm):\nReleased by Microsoft in April 2004.\nAddressed a vulnerability in the Local Security Authority Subsystem Service (LSASS) exploited by the Sasser\nworm.\nImportance: Helped prevent the Sasser worm from infecting millions of computers by exploiting the LSASS\nvulnerability, causing widespread network disruptions.\nMS03-026 (Blaster Worm):\nReleased by Microsoft in July 2003.\nAddressed a critical vulnerability in the Windows DCOM RPC interface exploited by the Blaster worm.\nImportance: Critical in stopping the spread of the Blaster worm, which affected hundreds of thousands of\ncomputers, causing network congestion and system reboots.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n58 / 93\n\n\nBest Practices in Patch Management\nBest Practices:\nRegularly scan systems for vulnerabilities.\nTest patches in a non-production environment before deployment.\nAutomate the patching process where possible to ensure consistency.\nKeep a backup before applying critical patches.\nEducate users about the importance of security updates.\nAdvantages:\nPatch management is a critical component of cybersecurity.\nA well-defined patch management process helps in mitigating",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 48,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "cal patches.\nEducate users about the importance of security updates.\nAdvantages:\nPatch management is a critical component of cybersecurity.\nA well-defined patch management process helps in mitigating the\nrisks posed by worms and other malware.\nRegular updates and adherence to best practices ensure the security\nand reliability of systems.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n59 / 93\n\n\nIntroduction to Access Control Management\nAccess control determines who is allowed to access or modify\ninformation in a system.\nIt is a critical component of cybersecurity, preventing unauthorized\naccess.\nHelps in reducing the spread of worms by limiting access based on\nuser roles and permissions.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n60 / 93\n\n\nImportance of Access Control in Worm Prevention\nMinimizes Attack Surface\nRestricting access to sensitive parts of the system reduces the number of potential entry points\nfor worms, minimizing the overall attack surface.\nEnsures Accountability\nAccess control mechanisms often include logging and monitoring features that track user\nactivities, helping to quickly identify and isolate co",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 49,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "mizing the overall attack surface.\nEnsures Accountability\nAccess control mechanisms often include logging and monitoring features that track user\nactivities, helping to quickly identify and isolate compromised accounts.\nEnforces Least Privilege Principle\nEnsures that users and applications have only the minimal access necessary to perform their\ntasks, limiting the ability of worms to exploit privileges to spread across systems.\nSegmentation of Network Resources\nAccess control can segment network resources, creating isolated environments where worms\ncannot easily propagate across different segments of the network.\nSupports Incident Response\nAccess control can be used to quickly revoke or modify access rights during a worm infection,\nhelping to contain and mitigate the impact.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n61 / 93\n\n\nTypes of Access Control Models\nDiscretionary Access Control (DAC):\nAccess is based on the identity of users and groups.\nEach resource has an Access Control List (ACL) specifying which users\ncan access it.\nMandatory Access Control (MAC):\nAccess decisions are based on predefined policies and security labels.\nTypically used in",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 50,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "esource has an Access Control List (ACL) specifying which users\ncan access it.\nMandatory Access Control (MAC):\nAccess decisions are based on predefined policies and security labels.\nTypically used in government and military applications.\nRole-Based Access Control (RBAC):\nAccess is granted based on user roles within an organization.\nSimplifies management by assigning permissions to roles rather than\nindividuals.\nAttribute-Based Access Control (ABAC):\nAccess is determined by evaluating attributes (e.g., user attributes,\nresource attributes).\nOffers flexibility and fine-grained access control.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n62 / 93\n\n\nAccess Control Algorithm for Worm Prevention\nAlgorithm Steps\nInput: User request R, Access Control Policy P, User attributes U,\nResource attributes Res.\nOutput: Access granted or denied.\n1 Step 1: Validate the user identity U and resource Res.\n2 Step 2: Check the access control policy P for user role R and\ncorresponding permissions.\n3 Step 3: Evaluate conditions based on attributes (ABAC model):\nIf (U.role = P.role) ∧(Res.type = P.resource type) ⇒Grant Access\n4 Step 4: Log the access request and outcome.\n5 St",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 51,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ponding permissions.\n3 Step 3: Evaluate conditions based on attributes (ABAC model):\nIf (U.role = P.role) ∧(Res.type = P.resource type) ⇒Grant Access\n4 Step 4: Log the access request and outcome.\n5 Step 5: If access is denied, alert the system administrator.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n63 / 93\n\n\nScenario Setup\nUser Request (R): Alice attempts to access a critical server.\nUser Attributes (U):\nName: Alice\nRole: System Administrator\nDepartment: IT\nResource Attributes (Res):\nResource Name: critical server 01\nResource Type: Critical Server\nDepartment: IT\nAccess Control Policy (P):\nRole required: System Administrator\nResource type: Critical Server\nDepartment: IT\nPermissions: Read, Write, Execute\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n64 / 93\n\n\nAlgorithm Execution\nStep-by-Step Execution\n1\nValidate User and Resource: Alice and critical server 01 are valid.\n2\nCheck Access Control Policy:\nAlice’s Role: System Administrator (Matches)\nResource Type: Critical Server (Matches)\nDepartment: IT (Matches)\n3\nEvaluate Conditions:\n(U.role = P.role) ∧(Res.type = P.resource type) ∧(U.department = P.department) ⇒Grant",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 52,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "m Administrator (Matches)\nResource Type: Critical Server (Matches)\nDepartment: IT (Matches)\n3\nEvaluate Conditions:\n(U.role = P.role) ∧(Res.type = P.resource type) ∧(U.department = P.department) ⇒Grant Access\n4\nLog Outcome: ”Access request by Alice to critical server 01 granted.”\n5\nAlert: Not required, access was granted.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n65 / 93\n\n\nResult\nAccess granted to Alice for read, write, and execute operations on\ncritical server 01.\nAccess request and outcome are logged for audit purposes.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n66 / 93\n\n\nAccess Control Algorithm Example\nExample Scenario\nUser Request: Alice requests access to the financial report R.\nAccess Control Policy: Policy P requires that only users with the role ”Manager” can access financial reports.\nUser Attributes: Alice’s role U.role = ”Manager”.\nResource Attributes: The resource type Res.type = ”Financial Report”.\nOutput: Access granted.\n1\nStep 1: Validate Alice’s identity U and the requested resource Res.\n2\nStep 2: Check the access control policy P for Alice’s role U.role = ”Manager” and corresponding permissions.",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 53,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "t: Access granted.\n1\nStep 1: Validate Alice’s identity U and the requested resource Res.\n2\nStep 2: Check the access control policy P for Alice’s role U.role = ”Manager” and corresponding permissions.\n3\nStep 3: Evaluate the following condition:\nIf (U.role = ”Manager”) ∧(Res.type = ”Financial Report”) ⇒Grant Access\nSince Alice’s role is ”Manager” and the resource type is ”Financial Report”, the condition is true.\n4\nStep 4: Log Alice’s access request and the outcome (Access granted).\n5\nStep 5: No alert is necessary as access is granted.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n67 / 93\n\n\nDetailed ABAC Algorithm for Worm Prevention\nAlgorithm Steps\nInput: User request R, ABAC Policy Pabac, User attributes U, Resource attributes Res.\nOutput: Access granted or denied.\n1\nStep 1: Extract attributes: {U.role, U.department, U.security level, . . .} and {Res.type, Res.sensitivity level, . . .}.\n2\nStep 2: Match user attributes against policy:\nIf (U.department = Pabac.department) ∧(U.security level ≥Res.sensitivity level) ⇒Grant Access\n3\nStep 3: Evaluate any additional conditions defined in Pabac:\nIf ∀i (U.attributei = Pabac.attributei) ⇒Grant Access\n4\nStep 4:",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 54,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "abac.department) ∧(U.security level ≥Res.sensitivity level) ⇒Grant Access\n3\nStep 3: Evaluate any additional conditions defined in Pabac:\nIf ∀i (U.attributei = Pabac.attributei) ⇒Grant Access\n4\nStep 4: Log access request and decision.\n5\nStep 5: If denied, notify security monitoring system.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n68 / 93\n\n\nScenario Setup\nUser Request (R): Bob attempts to access a confidential file.\nUser Attributes (U):\nName: Bob\nRole: Manager\nDepartment: IT\nSecurity Level: 6\nResource Attributes (Res):\nResource Name: confidential file.txt\nResource Type: File\nSensitivity Level: 5\nLocation: Internal Server\nABAC Policy (Pabac):\nRequired Department: IT\nMinimum Security Level: 5\nAdditional Condition: User role must be Manager or above\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n69 / 93\n\n\nAlgorithm Execution\nStep-by-Step Execution\n1\nExtract Attributes:\nU = {Manager, IT, 6},\nRes = {File, 5}\n2\nMatch User Attributes Against Policy:\nU.department = Pabac.department\n(IT matches IT)\nU.security level ≥Res.sensitivity level\n(6 ≥5)\n3\nEvaluate Additional Conditions:\nUser role = Manager ≥Manager\n(Condition met)\n4\nL",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 55,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ibutes Against Policy:\nU.department = Pabac.department\n(IT matches IT)\nU.security level ≥Res.sensitivity level\n(6 ≥5)\n3\nEvaluate Additional Conditions:\nUser role = Manager ≥Manager\n(Condition met)\n4\nLog Outcome: ”Access request by Bob for confidential file.txt was granted.”\n5\nNotify if Denied: Not required, access was granted.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n70 / 93\n\n\nResult\nAccess is granted to Bob for the confidential file.\nThe access request and outcome are logged.\nNo notification sent to the security monitoring system.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n71 / 93\n\n\nDetailed ABAC Algorithm Example\nExample Scenario\nUser Request: Bob requests access to a classified project file R.\nABAC Policy: Policy Pabac requires that the user must be in the ”Research” department and have a security level of 5\nor higher to access classified project files.\nUser Attributes:\nU.role = ”Researcher”\nU.department = ”Research”\nU.security level = 5\nResource Attributes:\nRes.type = ”Classified Project File”\nRes.sensitivity level = 4\nOutput: Access granted.\n1\nStep 1: Extract attributes:\n{U.role = ”Researcher”, U.departmen",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 56,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "arch”\nU.security level = 5\nResource Attributes:\nRes.type = ”Classified Project File”\nRes.sensitivity level = 4\nOutput: Access granted.\n1\nStep 1: Extract attributes:\n{U.role = ”Researcher”, U.department = ”Research”, U.security level = 5}\n{Res.type = ”Classified Project File”, Res.sensitivity level = 4}\n2\nStep 2: Match user attributes against policy:\nIf (U.department = Pabac.department = ”Research”)\n∧(U.security level = 5 ≥Res.sensitivity level = 4)\n⇒Grant Access\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n72 / 93\n\n\nDetailed ABAC Algorithm Example\nExample Scenario\n3\nStep 3: Evaluate any additional conditions defined in Pabac:\nNo additional conditions apply, so Grant Access\n4\nStep 4: Log Bob’s access request and the decision (Access granted).\n5\nStep 5: Since access is granted, no notification to the security monitoring system is needed.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n73 / 93\n\n\nDetailed RBAC Algorithm for Worm Prevention\nAlgorithm Steps\nInput: User role U.role, RBAC Policy Prbac.\nOutput: Access granted or denied.\n1 Step 1: Identify user’s role U.role.\n2 Step 2: Retrieve permissions associated with U.role",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 57,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "m Prevention\nAlgorithm Steps\nInput: User role U.role, RBAC Policy Prbac.\nOutput: Access granted or denied.\n1 Step 1: Identify user’s role U.role.\n2 Step 2: Retrieve permissions associated with U.role from Prbac.\n3 Step 3: Check if the requested action is within the permissions:\nIf R.action ∈Prbac.permissions ⇒Grant Access\n4 Step 4: Log the access request and outcome.\n5 Step 5: If access is denied, generate a security incident report.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n74 / 93\n\n\nDetailed RBAC Algorithm Example\nExample Scenario\nUser Role: John is assigned the role of ”Network Administrator” U.role = ”Network Admin”.\nRBAC Policy: The RBAC Policy Prbac specifies that the ”Network Admin” role has permissions to ”Monitor Traffic”\nand ”Configure Routers.”\nOutput: Access granted or denied based on John’s role and the requested action.\n1\nStep 1: Identify John’s role U.role = ”Network Admin”.\n2\nStep 2: Retrieve permissions associated with the ”Network Admin” role from Prbac.\nPermissions retrieved: ”Monitor Traffic,” ”Configure Routers.”\n3\nStep 3: Check if the requested action is within the permissions:\nRequested action: ”Monitor Traffic”\nIf R.action",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 58,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "dmin” role from Prbac.\nPermissions retrieved: ”Monitor Traffic,” ”Configure Routers.”\n3\nStep 3: Check if the requested action is within the permissions:\nRequested action: ”Monitor Traffic”\nIf R.action = ”Monitor Traffic” ∈Prbac.permissions ⇒Grant Access\nSince ”Monitor Traffic” is within the permissions, access is granted.\n4\nStep 4: Log the access request and outcome (Access granted).\n5\nStep 5: No security incident report is generated as access is granted.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n75 / 93\n\n\nDetailed DAC Algorithm for Worm Prevention\nAlgorithm Steps\nInput: User U, Resource Res, DAC Policy Pdac.\nOutput: Access granted or denied.\n1\nStep 1: Check if user U is the owner of the resource Res.\n2\nStep 2: Evaluate access rights from Pdac:\nIf (U = Res.owner) ∨(U.role = admin) ⇒Grant Access\n3\nStep 3: If no explicit permission is found, deny access.\n4\nStep 4: Log the access request and outcome.\n5\nStep 5: If denied, escalate to owner review.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n76 / 93\n\n\nDetailed DAC Algorithm Example\nExample Scenario\nUser: Alice requests access to a proprietary design document Res.\nReso",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 59,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n76 / 93\n\n\nDetailed DAC Algorithm Example\nExample Scenario\nUser: Alice requests access to a proprietary design document Res.\nResource Owner: The document is owned by Bob Res.owner = ”Bob”.\nDAC Policy: The policy Pdac specifies that access is granted if the user is the owner or an admin.\nOutput: Access granted or denied.\n1\nStep 1: Check if Alice U is the owner of the resource Res:\nU = ”Alice”\nRes.owner = ”Bob”\nAlice is not the owner.\n2\nStep 2: Evaluate access rights from Pdac:\nIf (U = ”Alice” ̸= ”Bob”) ∨(U.role = admin)\n⇒Grant Access\nSince Alice is neither the owner nor an admin, access is denied.\n3\nStep 3: No explicit permission is found for Alice. Access is denied.\n4\nStep 4: Log Alice’s access request and the outcome (Access denied).\n5\nStep 5: Since access is denied, escalate the request to the resource owner, Bob, for review.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n77 / 93\n\n\nBest Practices for Implementing Access Control\nRegularly update access control policies to adapt to new threats.\nUse the principle of least privilege: grant minimum necessary\npermissions.\nImplement mul",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 60,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "est Practices for Implementing Access Control\nRegularly update access control policies to adapt to new threats.\nUse the principle of least privilege: grant minimum necessary\npermissions.\nImplement multi-factor authentication (MFA) for sensitive operations.\nConduct periodic audits and reviews of access control settings.\nEducate users about the importance of secure access practices.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n78 / 93\n\n\nImportant Notes\nEffective access control is essential to prevent unauthorized access\nand reduce worm propagation.\nDifferent models (DAC, MAC, RBAC, ABAC) offer varying levels of\ncontrol and flexibility.\nImplementing best practices ensures the security and integrity of\nsensitive information.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n79 / 93\n\n\nNetwork Segmentation for Worm Prevention\nOverview\nNetwork segmentation involves dividing a network into smaller, isolated segments to limit the spread of worms and other\nmalicious activities. This approach enhances security by controlling traffic flow and reducing the attack surface.\nAlgorithm Steps\nInput: Network topology N, Segmentation policy",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 61,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ad of worms and other\nmalicious activities. This approach enhances security by controlling traffic flow and reducing the attack surface.\nAlgorithm Steps\nInput: Network topology N, Segmentation policy S, Traffic rules T , Security requirements R.\nOutput: Segmented network with defined security zones.\n1\nStep 1: Analyze the network topology N.\nIdentify all network nodes, devices, and connections.\nN = {Node1, Node2, . . . , Noden}\n2\nStep 2: Define segmentation policy S.\nDetermine the criteria for segmenting the network, such as based on departments, functions, or sensitivity of\ndata.\nS = {Segment1, Segment2, . . . , Segmentk}\n3\nStep 3: Implement traffic rules T between segments.\nDefine access controls and communication rules for traffic between segments.\nTij =\n(\nAllowed\nif Segmenti and Segmentj are permitted to communicate\nDenied\notherwise\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n80 / 93\n\n\nNetwork Segmentation for Worm Prevention\nOverview\n1\nStep 4: Apply security controls R within each segment.\nImplement security measures such as firewalls, intrusion detection systems, and access controls tailored to each\nsegment’s requirements.\nR = {Firewall Rules,",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 62,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "y security controls R within each segment.\nImplement security measures such as firewalls, intrusion detection systems, and access controls tailored to each\nsegment’s requirements.\nR = {Firewall Rules, IDS, Access Controls}\n2\nStep 5: Monitor and maintain segmented network.\nContinuously monitor traffic and enforce policies to ensure the effectiveness of segmentation.\nMonitor(N, S, T, R)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n81 / 93\n\n\nNetwork Segmentation for Worm Prevention\nExample Scenario\nA company implements network segmentation to prevent the spread of a\nworm infection. The network is divided into four segments:\nDevelopment\nMarketing\nFinance\nHR\nThe aim is to contain any worm infection within a single segment and\nprevent it from spreading to others.\nImplementation Steps\nInput: Network topology N, Segmentation policy S, Traffic rules T , Security controls C.\nOutput: Secured and isolated network segments.\n1\nStep 1: Segment the network N.\nDefine segments based on departments.\nN = {Dev, Mkt, Fin, HR}\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n82 / 93\n\n\nNetwork Segmentation for Worm Prevention\nImplementation Ste",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 63,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "gments based on departments.\nN = {Dev, Mkt, Fin, HR}\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n82 / 93\n\n\nNetwork Segmentation for Worm Prevention\nImplementation Steps\n1\nStep 2: Define access rules T between segments.\nControl which segments can communicate with each other.\nTij =\n(\nAllowed\nif Segmenti and Segmentj are permitted to communicate\nDenied\notherwise\nExample:\nTDev, Mkt = Allowed,\nTDev, Fin = Denied\n2\nStep 3: Implement security controls C for each segment.\nApply firewalls, IDS, and access controls.\nC = {Firewall for Dev, IDS for Mkt, Access Controls for HR}\n3\nStep 4: Monitor traffic between segments.\nTrack and analyze traffic to detect any anomalies or attempts to breach segmentation.\nMonitor(N, T, C)\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n83 / 93\n\n\nNetwork Segmentation for Worm Prevention\nNumerical Example\nConsider a network with the following topology and segmentation policy:\nNetwork Topology N:\nN = {A, B, C, D, E}\nSegmentation Policy S:\nS = {Segment1 = {A, B}, Segment2 = {C}, Segment3 = {D, E}}\nTraffic Rules T :\nTij =\n(\nAllowed\nif Segmenti and Segmentj are permitted to communicate\nDenied\notherwise\nF",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 64,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "B, C, D, E}\nSegmentation Policy S:\nS = {Segment1 = {A, B}, Segment2 = {C}, Segment3 = {D, E}}\nTraffic Rules T :\nTij =\n(\nAllowed\nif Segmenti and Segmentj are permitted to communicate\nDenied\notherwise\nFor example:\nT12 = Allowed,\nT13 = Denied,\nT23 = Allowed,\nT24 = Denied\nSecurity Controls R:\nR = {Firewalls, IDS, Access Controls}\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n84 / 93\n\n\nNetwork Segmentation for Worm Prevention\nNumerical Example (continued)\nApplying the policy and rules:\nFor Segment 1 (Nodes A, B):\nTraffic Rules:\nT12 = Allowed,\nFirewalls:Allow internal segment communication.\nFor Segment 2 (Node C):\nTraffic Rules:\nT13 = Denied,\nIDS: Monitor traffic to/from Segments 1 and 3.\nFor Segment 3 (Nodes D, E):\nTraffic Rules:\nT24 = Denied,\nAccess Controls: Restrict external access to segment.\nMonitoring:\nMonitor(N, S, T, R) = Evaluate effectiveness of segmentation and security controls.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n85 / 93\n\n\nLeast Privilege Principle for Worm Prevention\nOverview\nThe Least Privilege Principle dictates that users and systems should be granted the minimum level of access necessary to\nperfo",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 65,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "5, 2024\n85 / 93\n\n\nLeast Privilege Principle for Worm Prevention\nOverview\nThe Least Privilege Principle dictates that users and systems should be granted the minimum level of access necessary to\nperform their functions. This principle helps to limit the spread of worms and other malicious threats by minimizing the\npotential damage that can be caused by compromised accounts or systems.\nImplementation Steps\nInput: User roles R, Resource access requirements A, Security policy P , Current access levels C.\nOutput: Restricted access permissions.\n1\nStep 1: Identify user roles R and their required access levels.\nDefine roles based on job functions and responsibilities.\nR = {Role1, Role2, . . . , Rolek}\n2\nStep 2: Assess access requirements A for each role.\nDetermine the minimum access needed for each role to perform its duties.\nAi = {Resource1, Resource2, . . . , Resourcem}\n3\nStep 3: Define security policy P based on least privilege.\nImplement access controls to enforce the least privilege principle.\nPij =\n(\nAllowed\nif Rolei requires access to Resourcej\nDenied\notherwise\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n86 / 93\n\n\nLeast Privilege Principle for Worm",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 66,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ciple.\nPij =\n(\nAllowed\nif Rolei requires access to Resourcej\nDenied\notherwise\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n86 / 93\n\n\nLeast Privilege Principle for Worm Prevention\nImplementation Steps\n5\nStep 4: Review and adjust current access levels C.\nAudit existing permissions and adjust to align with the least privilege policy.\nCi = {Access1, Access2, . . . , Accessn}\n6\nStep 5: Monitor and enforce compliance with the least privilege policy.\nContinuously review access levels and adjust as necessary to maintain minimal access.\nMonitor(R, A, C, P )\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n87 / 93\n\n\nExample: Least Privilege Principle for Worm Prevention\nImplementation Steps\nInput: User roles R, Resource access requirements A, Security policy P , Current access levels C.\nOutput: Restricted access permissions.\n1\nStep 1: Identify user roles R and their required access levels.\nDefine roles based on job functions and responsibilities.\nR = {Admin, Developer, Analyst}\n2\nStep 2: Assess access requirements A for each role.\nDetermine the minimum access needed for each role to perform its duties.\nAAdmin = {Database, Server,",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 67,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "nsibilities.\nR = {Admin, Developer, Analyst}\n2\nStep 2: Assess access requirements A for each role.\nDetermine the minimum access needed for each role to perform its duties.\nAAdmin = {Database, Server, Configuration}\nADeveloper = {Source Code, Development Environment}\nAAnalyst = {Reports, Analytics Tools}\n3\nStep 3: Define security policy P based on least privilege.\nImplement access controls to enforce the least privilege principle.\nPAdmin, Database = Allowed\nPDeveloper, Database = Denied\nPAnalyst, Reports = Allowed\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n88 / 93\n\n\nLeast Privilege Principle for Worm Prevention\nImplementation Steps\n5\nStep 4: Review and adjust current access levels C.\nAudit existing permissions and adjust to align with the least privilege policy.\nCAdmin = {Database, Server, Configuration}\nCDeveloper = {Source Code, Development Environment}\nCAnalyst = {Reports, Analytics Tools}\n6\nStep 5: Monitor and enforce compliance with the least privilege policy.\nContinuously review access levels and adjust as necessary to maintain minimal access.\nMonitor(R, A, C, P ) →Regularly review and update access permissions\nAdarsh Kumar\nAdarsh[dot]Kumar[a",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 68,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "ilege policy.\nContinuously review access levels and adjust as necessary to maintain minimal access.\nMonitor(R, A, C, P ) →Regularly review and update access permissions\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n89 / 93\n\n\nExample : Least Privilege Principle for Worm Prevention\nImplementation Steps\nInput: User roles R, Resource access requirements A, Security policy P , Current access levels C.\nOutput: Restricted access permissions.\n1\nStep 1: Identify user roles R and their required access levels.\nDefine roles based on job functions and responsibilities.\nR = {Admin, Developer, Analyst}\nExample Roles and Responsibilities:\nAdmin: Full access to system configuration and databases\nDeveloper: Access to source code and development tools\nAnalyst: Access to reports and analytical tools\n2\nStep 2: Assess access requirements A for each role.\nDetermine the minimum access needed for each role.\nAAdmin = {Database, Server, Configuration}\nADeveloper = {Source Code, Development Environment}\nAAnalyst = {Reports, Analytics Tools}\nExample Access Requirements:\nAdmin: Required access to all critical resources\nDeveloper: Required access to only development-related resour",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 69,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "velopment Environment}\nAAnalyst = {Reports, Analytics Tools}\nExample Access Requirements:\nAdmin: Required access to all critical resources\nDeveloper: Required access to only development-related resources\nAnalyst: Required access to only report-related resources\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n90 / 93\n\n\nExample : Least Privilege Principle for Worm Prevention\nImplementation Steps\n3\nStep 3: Define security policy P based on least privilege.\nImplement access controls to enforce the least privilege principle.\nPAdmin, Database = Allowed\nPDeveloper, Database = Denied\nPAnalyst, Reports = Allowed\nExample Policy Rules:\nAdmin can access all critical resources\nDeveloper cannot access the database or server configurations\nAnalyst can access only the reports\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n91 / 93\n\n\nExample : Least Privilege Principle for Worm Prevention\nImplementation Steps\n4\nStep 4: Review and adjust current access levels C.\nAudit existing permissions and adjust to align with the least privilege policy.\nCAdmin = {Database, Server, Configuration}\nCDeveloper = {Source Code, Development Environment}\nCAnaly",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 70,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "t access levels C.\nAudit existing permissions and adjust to align with the least privilege policy.\nCAdmin = {Database, Server, Configuration}\nCDeveloper = {Source Code, Development Environment}\nCAnalyst = {Reports, Analytics Tools}\nExample Current Access Levels:\nAdmin: Access to all resources as required\nDeveloper: Access to development-related resources only\nAnalyst: Access to report-related resources only\n5\nStep 5: Monitor and enforce compliance with the least privilege policy.\nContinuously review access levels and adjust as necessary to maintain minimal access.\nMonitor(R, A, C, P ) →Regularly review and update access permissions\nExample Monitoring Actions:\nPerform regular audits of access permissions\nUpdate permissions based on changes in job roles or responsibilities\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n92 / 93\n\n\nThank You\nThank You!\nFor your attention and participation\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nSeptember 5, 2024\n93 / 93",
    "source_file": "2025-11-24_10-03-35_UNIT 2.pdf",
    "chunk_index": 71,
    "timestamp": "2025-11-24_10-03-35"
  },
  {
    "text": "Transposition Ciphers\nCryptography: Transposition Ciphers\nUnit III\nAdarsh Kumar\nProfessor, Systems, School of Computer Science, UPES, Dehradun,\nUttarakhand, India\nadarsh.kumar@ddn.upes.ac.in\nMarch 9, 2025\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n1 / 16\n\n\nTransposition Ciphers\nIntroduction to Transposition Ciphers\nDefinition\nTransposition Ciphers are cryptographic techniques where the\npositions of characters in the plaintext are shifted according to a\nregular system.\nCharacteristics\nUnlike substitution ciphers, transposition ciphers do not change the\ncharacters but rearrange them.\nCommon Examples\nRail Fence Cipher: A simple zigzag pattern rearrangement.\nColumnar Transposition Cipher: Uses a keyword to\ndetermine column order.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n2 / 16\n\n\nTransposition Ciphers\nRail Fence Cipher\nDescription\nA form of transposition cipher that writes the message in a\nzigzag or “rail fence” pattern.\nAfter writing out the message in multiple “rails,” we read\neach rail sequentially to form the ciphertext.\nExample\nPlaintext: HELLO WORLD\nArrange in two rails:\nRow 1: H L O W R D\nRow 2: E L O L\nCiphertext: H",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 0,
    "timestamp": "2025-11-24_10-42-19"
  },
  {
    "text": "writing out the message in multiple “rails,” we read\neach rail sequentially to form the ciphertext.\nExample\nPlaintext: HELLO WORLD\nArrange in two rails:\nRow 1: H L O W R D\nRow 2: E L O L\nCiphertext: HLOWRD ELOOL\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n3 / 16\n\n\nTransposition Ciphers\nColumnar Transposition Cipher\nDescription\nIn a columnar transposition cipher, the plaintext is written in rows, and the\ncolumns are rearranged according to a specific keyword.\nEach letter in the keyword corresponds to a column and determines the order in\nwhich columns are read.\nExample\nPlaintext: ATTACK AT DAWN\nKeyword: CAB\nArrange in columns:\nC\nA\nB\nA\nT\nT\nT\nA\nC\nK\nA\nT\nD\nA\nW\nN\n-\n-\nCiphertext: TAAA TCTW ATKDN\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n4 / 16\n\n\nTransposition Ciphers\nRoute Cipher\nDescription\nA Route Cipher writes the message in a grid, then reads it off\nin a set pattern.\nCommon patterns include spirals, zigzags, and other routes\nacross rows and columns.\nExample\nPlaintext: DEFEND THE EAST WALL\nWrite in a 3x5 grid:\nD\nE\nF\nE\nN\nD\nT\nH\nE\nA\nS\nT\nW\nA\nL\nCiphertext: DDS ETT FHW EEA NAL\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[do",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 1,
    "timestamp": "2025-11-24_10-42-19"
  },
  {
    "text": "oss rows and columns.\nExample\nPlaintext: DEFEND THE EAST WALL\nWrite in a 3x5 grid:\nD\nE\nF\nE\nN\nD\nT\nH\nE\nA\nS\nT\nW\nA\nL\nCiphertext: DDS ETT FHW EEA NAL\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n5 / 16\n\n\nTransposition Ciphers\nScytale Cipher\nDescription\nAncient Greek cipher, using a strip of parchment wrapped\naround a rod (scytale).\nThe message is only readable when wrapped around a rod of\nthe same diameter.\nExample\nPlaintext: HELLOWORLD\nWrapped around a rod:\nH E L L O\nW O R L D\nCiphertext: HWEOLRLLOD\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n6 / 16\n\n\n[Image]: a close up of a tube of paper with writing on it\n\nTransposition Ciphers\nDouble Transposition Cipher\nDescription\nApplies two successive columnar transpositions with different\nkeys.\nCreates additional complexity for decryption.\nExample\nPlaintext: SECURITY\nFirst key: 4312\nSecond key: 3142\nAfter applying both transpositions, Ciphertext: ECSUITYR\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n7 / 16\n\n\nTransposition Ciphers\nDouble Transposition Cipher\nExample\nStep 1: First Transposition (Key: 4312)\nWrite the plaintext in columns according to the order",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 2,
    "timestamp": "2025-11-24_10-42-19"
  },
  {
    "text": "dn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n7 / 16\n\n\nTransposition Ciphers\nDouble Transposition Cipher\nExample\nStep 1: First Transposition (Key: 4312)\nWrite the plaintext in columns according to the order of the key (4312). The number\nrepresents the order in which the columns will be rearranged.\nGrid before the first transposition:\n4\n3\n1\n2\nS\nE\nC\nU\nR\nI\nT\nY\nRearrange columns according to key 4312:\nC\nU\nE\nS\nT\nY\nI\nR\nAfter the first transposition, the text becomes: CTUYEISR\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n8 / 16\n\n\nTransposition Ciphers\nDouble Transposition Cipher\nExample\nStep 2: Second Transposition (Key: 3142)\nNow apply the second transposition using the key 3142. Write the\nresult of the first transposition in columns:\n3\n1\n4\n2\nC\nT\nU\nY\nE\nI\nS\nR\nRearrange columns according to key 3142:\nT\nY\nC\nU\nI\nR\nE\nS\nAfter the second transposition, the ciphertext becomes: TIYRCEUS\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n9 / 16\n\n\nTransposition Ciphers\nMyszkowski Transposition Cipher\nDescription:\nSimilar to columnar transposition but uses repeated characters\nin the keyword.\nColumns with the same letter are read in sequence.\nExample:\nPla",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 3,
    "timestamp": "2025-11-24_10-42-19"
  },
  {
    "text": "tion Ciphers\nMyszkowski Transposition Cipher\nDescription:\nSimilar to columnar transposition but uses repeated characters\nin the keyword.\nColumns with the same letter are read in sequence.\nExample:\nPlaintext: HELLO WORLD\nKeyword: APPLE (A, P, P, L, E)\nWrite in columns and read by columns based on the order of\nthe keyword.\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n10 / 16\n\n\nTransposition Ciphers\nDisrupted Transposition Cipher\nDescription\nDivides text into sections that are scrambled or shifted.\nAdds additional complexity compared to regular transpositions.\nExample\nPlaintext: SECURE MESSAGE\nSplit into segments and scramble each.\nStep 1: Split the plaintext into segments. Split the plaintext SECURE MESSAGE into\n4-character segments:\nSECURE MESSAGE\n→\nSEGMENTS: {SECU, RE M, ESSA, GE}\nStep 2: Scramble each segment.\nFor each segment, rearrange the letters in a scrambled pattern:\nSECU becomes SCEU\nRE M becomes M RR\nESSA becomes ESSA\nGE remains EG\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n11 / 16\n\n\nTransposition Ciphers\nDisrupted Transposition Cipher\nStep 3: Combine the scrambled segments.\nAfter scrambling the segments, combine",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 4,
    "timestamp": "2025-11-24_10-42-19"
  },
  {
    "text": "rsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n11 / 16\n\n\nTransposition Ciphers\nDisrupted Transposition Cipher\nStep 3: Combine the scrambled segments.\nAfter scrambling the segments, combine them together:\nCiphertext: SCE UES GSM EGA\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n12 / 16\n\n\nTransposition Ciphers\nGrille Cipher\nDescription\nUses a grid with cut-out sections to reveal portions of text.\nThe grid is rotated to reveal additional characters.\nExample\nPlaintext: HELLO WORLD\nArrange plaintext in a grid:\nH\nE\nL\nL\nO\nW\nO\nR\nL\nD\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n13 / 16\n\n\nTransposition Ciphers\nGrille Cipher - Step 1\nStep 1: First Pass (No Rotation):\nRead the letters visible in the cut-out sections (first and third\ncolumns):\nRevealed: HLO\nStep 2: Second Pass (90° Rotation):\nAfter rotating the grid 90° clockwise, reveal the new letters:\nL\nO\nL\nE\nW\nO\nW\nR\nD\nR\nRevealed: LOW\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n14 / 16\n\n\nTransposition Ciphers\nGrille Cipher - Step 2\nStep 3: Third Pass (180° Rotation):\nRotate the grid 180° and reveal more letters:\nL\nW\nD\nL\nO\nO\nR\nH\nL\nR\nRevealed: LHD",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 5,
    "timestamp": "2025-11-24_10-42-19"
  },
  {
    "text": "s[dot]ac[dot]in\nMarch 9, 2025\n14 / 16\n\n\nTransposition Ciphers\nGrille Cipher - Step 2\nStep 3: Third Pass (180° Rotation):\nRotate the grid 180° and reveal more letters:\nL\nW\nD\nL\nO\nO\nR\nH\nL\nR\nRevealed: LHD\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n15 / 16\n\n\nTransposition Ciphers\nGrille Cipher - Step 3\nStep 4: Fourth Pass (270° Rotation):\nRotate the grid 270° and reveal the final set of characters:\nL\nE\nD\nL\nO\nR\nW\nH\nL\nD\nRevealed: LWR\nFinal Ciphertext: HLO LOW LHD LWR\nAdarsh Kumar\nAdarsh[dot]Kumar[at]ddn[dot]upes[dot]ac[dot]in\nMarch 9, 2025\n16 / 16",
    "source_file": "2025-11-24_10-42-19_UNIT 3_2.pdf",
    "chunk_index": 6,
    "timestamp": "2025-11-24_10-42-19"
  }
]